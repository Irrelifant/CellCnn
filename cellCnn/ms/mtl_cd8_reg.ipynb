{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cellCnn\n",
    "import importlib\n",
    "\n",
    "importlib.reload(cellCnn)\n",
    "import random\n",
    "import numpy as np\n",
    "### (from: https://github.com/eiriniar/CellCnn/blob/0413a9f49fe0831c8fe3280957fb341f9e028d2d/cellCnn/examples/NK_cell_ungated.ipynb ) AND https://github.com/eiriniar/CellCnn/blob/0413a9f49fe0831c8fe3280957fb341f9e028d2d/cellCnn/examples/PBMC.ipynb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cellCnn.ms.utils.helpers import get_min_mean_from_clusters, get_chunks\n",
    "from cellCnn.utils import mkdir_p\n",
    "from cellCnn.plotting import plot_results\n",
    "from cellCnn.ms.utils.helpers import get_chunks\n",
    "from cellCnn.ms.utils.helpers import print_regression_model_stats\n",
    "from cellCnn.plotting import plot_results\n",
    "from cellCnn.utils import mkdir_p\n",
    "from cellCnn.utils import save_results\n",
    "from cellCnn.ms.utils.helpers import get_fitted_model\n",
    "from cellCnn.ms.utils.helpers import split_test_valid_train\n",
    "from cellCnn.ms.utils.helpers import calc_frequencies, get_chunks_from_df\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "##### state vars\n",
    "cytokines = ['CCR2', 'CCR4', 'CCR6', 'CCR7', 'CXCR4', 'CXCR5', 'CD103', 'CD14', 'CD20', 'CD25', 'CD27', 'CD28', 'CD3',\n",
    "             'CD4', 'CD45RA', 'CD45RO', 'CD56', 'CD57', 'CD69', 'CD8', 'TCRgd', 'PD.1', 'GM.CSF', 'IFN.g', 'IL.10',\n",
    "             'IL.13', 'IL.17A', 'IL.2', 'IL.21', 'IL.22', 'IL.3', 'IL.4', 'IL.6', 'IL.9', 'TNF.a']\n",
    "infile = 'cohort_denoised_clustered_diagnosis_patients.csv'\n",
    "indir = 'data/input.nosync'\n",
    "outdir = 'out_ms_default'\n",
    "rand_seed = 123\n",
    "train_perc = 0.7\n",
    "test_perc = 0.3\n",
    "batch_size_pheno = 840 # deprecated  # so a size of 8425 is about equally sized in batches\n",
    "batch_size_cd4 = 550  # deprecated #so a size of 550 gets me 16 batches for cd4\n",
    "## information from ms_data project\n",
    "cluster_to_celltype_dict = {0: 'b', 1: 'cd4', 3: 'nkt', 8: 'cd8', 10: 'nk', 11: 'my', 16: 'dg'}\n",
    "outfolder = 'mtl_1'\n",
    "mkdir_p(outfolder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(16889, 38)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(rand_seed)\n",
    "mkdir_p(outdir)\n",
    "df = pd.read_csv(os.path.join(indir, infile), index_col=0)\n",
    "df = df.drop_duplicates()  ### reduces overfitting at cost of fewer data\n",
    "df.shape\n",
    "##### no duplicates in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# pitch: key = gate_source, value = dict{diagnosis: df OR freq?}\n",
    "rrms_df = df[df['diagnosis'] == 'RRMS']\n",
    "rrms_patients2df = {id: patient_df.drop(columns=['diagnosis', 'gate_source']) for id, patient_df in\n",
    "                    rrms_df.groupby('gate_source')}\n",
    "nindc_df = df[df['diagnosis'] == 'NINDC']\n",
    "nindc_patients2df = {id: patient_df.drop(columns=['diagnosis', 'gate_source']) for id, patient_df in\n",
    "                     nindc_df.groupby('gate_source')}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### split by diagnosis state\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies: \n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#### here we could see freq differences across the 2 groups\n",
    "print('Frequencies: ')\n",
    "rrms_patients_freq = {id: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list=True) for id, patient_df in\n",
    "                      rrms_patients2df.items()}\n",
    "nindc_patients_freq = {id: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list=True) for id, patient_df\n",
    "                       in nindc_patients2df.items()}\n",
    "print('DONE')\n",
    "# we got 31 patients each"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### celltype frequencies\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/5d38cf1d6tvdyny38zb_66540000gn/T/ipykernel_77283/30090753.py:3: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "data": {
      "text/plain": "cluster      0    1   3    8   10  11  16\ngate_source                              \n3.0          60  119   6   30   5   5   0\n4.0          15   46   0   45   2   1  13\n5.0          33  131   0   70   2   2   4\n8.0          24  122   0   31  10  11   4\n9.0          72  270   2  137  11  10   4\n...          ..  ...  ..  ...  ..  ..  ..\n128.0         4    6   4    6   1   6   0\n130.0        24   82   2   56   8   4   0\n131.0        20   48   2   14  13   7   0\n132.0         8   35   7   16   1   1  10\n133.0        26   48   3   37   8  12   6\n\n[62 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>cluster</th>\n      <th>0</th>\n      <th>1</th>\n      <th>3</th>\n      <th>8</th>\n      <th>10</th>\n      <th>11</th>\n      <th>16</th>\n    </tr>\n    <tr>\n      <th>gate_source</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3.0</th>\n      <td>60</td>\n      <td>119</td>\n      <td>6</td>\n      <td>30</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>15</td>\n      <td>46</td>\n      <td>0</td>\n      <td>45</td>\n      <td>2</td>\n      <td>1</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>33</td>\n      <td>131</td>\n      <td>0</td>\n      <td>70</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8.0</th>\n      <td>24</td>\n      <td>122</td>\n      <td>0</td>\n      <td>31</td>\n      <td>10</td>\n      <td>11</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>9.0</th>\n      <td>72</td>\n      <td>270</td>\n      <td>2</td>\n      <td>137</td>\n      <td>11</td>\n      <td>10</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>128.0</th>\n      <td>4</td>\n      <td>6</td>\n      <td>4</td>\n      <td>6</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>130.0</th>\n      <td>24</td>\n      <td>82</td>\n      <td>2</td>\n      <td>56</td>\n      <td>8</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>131.0</th>\n      <td>20</td>\n      <td>48</td>\n      <td>2</td>\n      <td>14</td>\n      <td>13</td>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>132.0</th>\n      <td>8</td>\n      <td>35</td>\n      <td>7</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>133.0</th>\n      <td>26</td>\n      <td>48</td>\n      <td>3</td>\n      <td>37</td>\n      <td>8</td>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>62 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clusters_conf_table = pd.crosstab(df['gate_source'], df['cluster'])\n",
    "sns.heatmap(patients_clusters_conf_table, annot=False, vmax=100)\n",
    "plt.show()\n",
    "#plt.savefig('images/patient_vs_cluster_conf_table.png')\n",
    "patients_clusters_conf_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: batches created\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "\n",
    "\n",
    "# batch_sizes = [40,80,120, 160]\n",
    "batch_size_dict = dict()\n",
    "batch_sizes = [120]\n",
    "for batch_size in batch_sizes:\n",
    "    ### desease states 1 = RRMS and 0 = NINDC\n",
    "    selection_pool_rrms_cd8 = get_chunks_from_df(rrms_patients2df,\n",
    "                           freq_df=rrms_patients_freq,\n",
    "                           desease_state=1,\n",
    "                           batch_size=batch_size)\n",
    "    selection_pool_nindc_cd8 = get_chunks_from_df(nindc_patients2df,\n",
    "                           freq_df=nindc_patients_freq,\n",
    "                           desease_state=0,\n",
    "                           batch_size=batch_size)\n",
    "\n",
    "    # make sure list are equally long:\n",
    "    if len(selection_pool_rrms_cd8) > len(selection_pool_nindc_cd8):\n",
    "        selection_pool_rrms_cd8 = selection_pool_rrms_cd8[:len(selection_pool_nindc_cd8)]\n",
    "    elif len(selection_pool_rrms_cd8) < len(selection_pool_nindc_cd8):\n",
    "        selection_pool_nindc_cd8 = selection_pool_nindc_cd8[:len(selection_pool_rrms_cd8)]\n",
    "\n",
    "    all_chunks = selection_pool_rrms_cd8 + selection_pool_nindc_cd8\n",
    "    np.random.shuffle(all_chunks)\n",
    "\n",
    "    X = [selection[0] for selection in all_chunks]\n",
    "    freqs = [selection[1] for selection in all_chunks]\n",
    "    Y = [selection[2] for selection in all_chunks]\n",
    "    batch_size_dict[batch_size] = (X, freqs, Y)\n",
    "\n",
    "print('DONE: batches created')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### Also ich brauch nicht mehr nach cell types in den batches suchen, es ist recht egal.\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "### CD8 Freq regression task + MTL\n",
    "model_container_cd8 = []\n",
    "stats_dict_reg_cd8 = dict()\n",
    "outdir_cd8 = 'mtl/cd8/'\n",
    "mkdir_p(outdir_cd8)\n",
    "mkdir_p(outdir_cd8+'models')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [25]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     25\u001B[0m     outdir_pheno_reg_cd8 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutdir_cd8\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/models/ms_reg_cd8_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatch_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_stl\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;66;03m# todo nsubset parameter maybe different\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m     model \u001B[38;5;241m=\u001B[39m get_fitted_model(X_train, X_valid, [y_train, cd8_train], [cd8_valid, y_valid],\n\u001B[1;32m     29\u001B[0m                              nsubset\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m,\n\u001B[1;32m     30\u001B[0m                              nfilters\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m35\u001B[39m], coeff_l1\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     31\u001B[0m                              max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, nrun\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     32\u001B[0m                              ncell\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m,\n\u001B[1;32m     33\u001B[0m                              per_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, regression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     34\u001B[0m                              outdir\u001B[38;5;241m=\u001B[39moutdir_pheno_reg_cd8, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, mtl_tasks\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     35\u001B[0m     model_container_cd8\u001B[38;5;241m.\u001B[39mappend(model)\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDONE building models\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/ms/utils/helpers.py:169\u001B[0m, in \u001B[0;36mget_fitted_model\u001B[0;34m(X_train, X_valid, y_train, y_valid, nrun, ncell, nsubset, nfilters, coeff_l2, coeff_l1, max_epochs, learning_rate, outdir, per_sample, regression, verbose, result, mtl_tasks)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;66;03m## parameters from PBMC example\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;66;03m###per_sample bei regression\u001B[39;00m\n\u001B[1;32m    163\u001B[0m model \u001B[38;5;241m=\u001B[39m CellCnn(nrun\u001B[38;5;241m=\u001B[39mnrun, ncell\u001B[38;5;241m=\u001B[39mncell, nsubset\u001B[38;5;241m=\u001B[39mnsubset,\n\u001B[1;32m    164\u001B[0m                 nfilter_choice\u001B[38;5;241m=\u001B[39mnfilters, learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate,\n\u001B[1;32m    165\u001B[0m                 coeff_l2\u001B[38;5;241m=\u001B[39mcoeff_l2, coeff_l1\u001B[38;5;241m=\u001B[39mcoeff_l1,\n\u001B[1;32m    166\u001B[0m                 max_epochs\u001B[38;5;241m=\u001B[39mmax_epochs, per_sample\u001B[38;5;241m=\u001B[39mper_sample,\n\u001B[1;32m    167\u001B[0m                 regression\u001B[38;5;241m=\u001B[39mregression, verbose\u001B[38;5;241m=\u001B[39mverbose, mtl_tasks\u001B[38;5;241m=\u001B[39mmtl_tasks)\n\u001B[0;32m--> 169\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_phenotypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mvalid_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_phenotypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_valid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m                  \u001B[49m\u001B[43moutdir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutdir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:159\u001B[0m, in \u001B[0;36mCellCnn.fit\u001B[0;34m(self, train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, train_samples, train_phenotypes, outdir, valid_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    123\u001B[0m         valid_phenotypes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, generate_valid_set\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;124;03m\"\"\" Trains a CellCnn model.\u001B[39;00m\n\u001B[1;32m    126\u001B[0m \n\u001B[1;32m    127\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;124;03m        - n_classes : number of output classes\u001B[39;00m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 159\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_phenotypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutdir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mvalid_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_phenotypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerate_valid_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mscale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnrun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnrun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mregression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mncell\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mncell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnsubset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnsubset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mper_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mper_sample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m                      \u001B[49m\u001B[43msubset_selection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubset_selection\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mmaxpool_percentages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaxpool_percentages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mnfilter_choice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnfilter_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mcoeff_l1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_l1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoeff_l2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_l2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatience\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdendrogram_cutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdendrogram_cutoff\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m                      \u001B[49m\u001B[43maccur_thres\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccur_thres\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmtl_tasks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmtl_tasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m res\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:313\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set, scale, quant_normed, nrun, regression, ncell, nsubset, per_sample, subset_selection, maxpool_percentages, nfilter_choice, learning_rate, coeff_l1, coeff_l2, dropout, dropout_p, max_epochs, patience, dendrogram_cutoff, accur_thres, verbose, mtl_tasks)\u001B[0m\n\u001B[1;32m    309\u001B[0m         valid_samples \u001B[38;5;241m=\u001B[39m normalize_outliers_to_control(ctrl_list, test_list)\n\u001B[1;32m    311\u001B[0m \u001B[38;5;66;03m# merge all input samples (X_train, X_valid)\u001B[39;00m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;66;03m# and generate an identifier for each of them (train_id, valid_id)\u001B[39;00m\n\u001B[0;32m--> 313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mmtl_tasks\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    314\u001B[0m     train_sample_ids \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;28mlen\u001B[39m(train_phenotypes))  \u001B[38;5;66;03m## todo mtl check, the ids are just\u001B[39;00m\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:313\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set, scale, quant_normed, nrun, regression, ncell, nsubset, per_sample, subset_selection, maxpool_percentages, nfilter_choice, learning_rate, coeff_l1, coeff_l2, dropout, dropout_p, max_epochs, patience, dendrogram_cutoff, accur_thres, verbose, mtl_tasks)\u001B[0m\n\u001B[1;32m    309\u001B[0m         valid_samples \u001B[38;5;241m=\u001B[39m normalize_outliers_to_control(ctrl_list, test_list)\n\u001B[1;32m    311\u001B[0m \u001B[38;5;66;03m# merge all input samples (X_train, X_valid)\u001B[39;00m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;66;03m# and generate an identifier for each of them (train_id, valid_id)\u001B[39;00m\n\u001B[0;32m--> 313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mmtl_tasks\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    314\u001B[0m     train_sample_ids \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;28mlen\u001B[39m(train_phenotypes))  \u001B[38;5;66;03m## todo mtl check, the ids are just\u001B[39;00m\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1147\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1144\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1147\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1162\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1159\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1161\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1162\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "importlib.reload(cellCnn.model)\n",
    "importlib.reload(cellCnn)\n",
    "importlib.reload(cellCnn.utils)\n",
    "from cellCnn.utils import *\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "from cellCnn import *\n",
    "\n",
    "\n",
    "kf_split = 2\n",
    "for batch_size, values, in batch_size_dict.items():\n",
    "    # for regression task stratified is wrong since there are no classes\n",
    "    freq_idx =3\n",
    "    X, cd8, y = values[0], values[1], values[2]\n",
    "    cd8 = [series[freq_idx] for series in cd8]\n",
    "\n",
    "    X_test, X_train, X_valid, cd8_test, cd8_train, cd8_valid, y_test, y_train, y_valid = split_test_train_valid(\n",
    "        X, cd8, y,\n",
    "        train_perc=train_perc,\n",
    "        test_perc=test_perc,\n",
    "        valid_perc=0.5)\n",
    "    X = np.array([*X_train, *X_valid])\n",
    "    cd8 = np.array([*cd8_train, *cd8_valid])\n",
    "    y = np.array([*y_train, *y_valid])\n",
    "    outdir_pheno_reg_cd8 = f'{outdir_cd8}/models/ms_reg_cd8_{batch_size}_stl'\n",
    "\n",
    "    # todo nsubset parameter maybe different\n",
    "    model = get_fitted_model(X_train, X_valid, [y_train, cd8_train], [cd8_valid, y_valid],\n",
    "                             nsubset=1000,\n",
    "                             nfilters=[3, 15, 25, 35], coeff_l1=0,\n",
    "                             max_epochs=100, nrun=30, learning_rate=None,\n",
    "                             ncell=200,\n",
    "                             per_sample=True, regression=True,\n",
    "                             outdir=outdir_pheno_reg_cd8, verbose=False, mtl_tasks=2)\n",
    "    model_container_cd8.append(model)\n",
    "print('DONE building models')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13141c8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1322abb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "mses = []\n",
    "\n",
    "# what predict does is: Iterating over the best 3 nets and return an array per net with the predictions for all samples!\n",
    "bs_idx = 1\n",
    "for i, model in enumerate(model_container_cd8):\n",
    "    stats_file = open(f\"{outdir_cd8}/stats_reg_{model.ncell}_{model.nsubset}.txt\", \"w+\")\n",
    "    stats_file.write(f\"Model {i}; Batchsize: {batch_sizes[bs_idx-1]}\\n\")\n",
    "    if bs_idx % kf_split == 0: ## when the kf split amount is reaches the next batchsize is applied\n",
    "        bs_idx = bs_idx +1\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "    #print_regression_model_stats(test_pred, b_test)\n",
    "    mse_test = mean_squared_error(y_test, test_pred[0])\n",
    "    mse_train = mean_squared_error(y_train, train_pred[0])\n",
    "    mse_valid = mean_squared_error(y_valid, valid_pred[0])\n",
    "    mses.append(mse_test)\n",
    "\n",
    "    stats_file.write('Desease: \\n')\n",
    "    stats_file.write(f'MSE y test {mse_test}\\n')\n",
    "    stats_file.write(f'MSE y train {mse_train}\\n')\n",
    "    stats_file.write(f'MSE y valid {mse_valid}\\n')\n",
    "\n",
    "    mse_test_cd8 = mean_squared_error(cd8_test, test_pred[1])\n",
    "    mse_train_cd8 = mean_squared_error(cd8_train, train_pred[1])\n",
    "    mse_valid_cd8 = mean_squared_error(cd8_valid, valid_pred[1])\n",
    "    mses.append(mse_test_cd8)\n",
    "\n",
    "    stats_file.write('Cd8: \\n')\n",
    "    stats_file.write(f'MSE y test {mse_test_cd8}\\n')\n",
    "    stats_file.write(f'MSE y train {mse_train_cd8}\\n')\n",
    "    stats_file.write(f'MSE y valid {mse_valid_cd8}\\n')\n",
    "    stats_file.write('\\n')\n",
    "    stats_file.close()\n",
    "print('DONE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
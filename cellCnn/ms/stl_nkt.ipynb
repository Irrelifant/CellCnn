{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cellCnn\n",
    "import importlib\n",
    "importlib.reload(cellCnn)\n",
    "import random\n",
    "import numpy as np\n",
    "### (from: https://github.com/eiriniar/CellCnn/blob/0413a9f49fe0831c8fe3280957fb341f9e028d2d/cellCnn/examples/NK_cell_ungated.ipynb ) AND https://github.com/eiriniar/CellCnn/blob/0413a9f49fe0831c8fe3280957fb341f9e028d2d/cellCnn/examples/PBMC.ipynb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cellCnn.ms.utils.helpers import get_min_mean_from_clusters, get_chunks\n",
    "from cellCnn.utils import mkdir_p\n",
    "from cellCnn.plotting import plot_results\n",
    "from cellCnn.ms.utils.helpers import get_chunks\n",
    "from cellCnn.ms.utils.helpers import print_regression_model_stats\n",
    "from cellCnn.plotting import plot_results\n",
    "from cellCnn.utils import mkdir_p\n",
    "from cellCnn.utils import save_results\n",
    "from cellCnn.ms.utils.helpers import get_fitted_model\n",
    "from cellCnn.ms.utils.helpers import split_test_valid_train\n",
    "from cellCnn.ms.utils.helpers import calc_frequencies, get_chunks_from_df\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##### state vars\n",
    "cytokines = ['CCR2', 'CCR4', 'CCR6', 'CCR7', 'CXCR4', 'CXCR5', 'CD103', 'CD14', 'CD20', 'CD25', 'CD27', 'CD28', 'CD3',\n",
    "             'CD4', 'CD45RA', 'CD45RO', 'CD56', 'CD57', 'CD69', 'CD8', 'TCRgd', 'PD.1', 'GM.CSF', 'IFN.g', 'IL.10',\n",
    "             'IL.13', 'IL.17A', 'IL.2', 'IL.21', 'IL.22', 'IL.3', 'IL.4', 'IL.6', 'IL.9', 'TNF.a']\n",
    "infile = 'cohort_denoised_clustered_diagnosis_patients.csv'\n",
    "indir = 'data/input.nosync'\n",
    "outdir = 'out_ms_default'\n",
    "rand_seed = 123\n",
    "train_perc = 0.7\n",
    "test_perc = 0.3\n",
    "batch_size_pheno = 840 # deprecated  # so a size of 8425 is about equally sized in batches\n",
    "batch_size_cd4 = 550  # deprecated #so a size of 550 gets me 16 batches for cd4\n",
    "## information from ms_data project\n",
    "cluster_to_celltype_dict = {0: 'b', 1: 'cd4', 3: 'nkt', 8: 'cd8', 10: 'nk', 11: 'my', 16: 'dg'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(rand_seed)\n",
    "mkdir_p(outdir)\n",
    "df = pd.read_csv(os.path.join(indir, infile), index_col=0)\n",
    "df = df.drop_duplicates()  ### reduces overfitting at cost of fewer data\n",
    "df.shape\n",
    "##### no duplicates in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "patients_clusters_conf_table = pd.crosstab(df['gate_source'], df['cluster'])\n",
    "sns.heatmap(patients_clusters_conf_table, annot=False, vmax=100)\n",
    "plt.show()\n",
    "#plt.savefig('images/patient_vs_cluster_conf_table.png')\n",
    "patients_clusters_conf_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Mean abundancies')\n",
    "print('b: ' + str(patients_clusters_conf_table.iloc[:,0].mean()))\n",
    "print('CD4: ' + str(patients_clusters_conf_table.iloc[:,1].mean()))\n",
    "print('NKT: ' + str(patients_clusters_conf_table.iloc[:,2].mean()))\n",
    "print('CD8: ' + str(patients_clusters_conf_table.iloc[:,3].mean()))\n",
    "print('NK: ' + str(patients_clusters_conf_table.iloc[:,4].mean()))\n",
    "print('My: ' + str(patients_clusters_conf_table.iloc[:,5].mean()))\n",
    "print('dg: ' + str(patients_clusters_conf_table.iloc[:,6].mean()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### This might be interesting, my NKT best value was for bs of 7 and my best CD8 was for 60\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pitch: key = gate_source, value = dict{diagnosis: df OR freq?}\n",
    "rrms_df = df[df['diagnosis'] == 'RRMS']\n",
    "rrms_patients2df = {id: patient_df.drop(columns=['diagnosis', 'gate_source']) for id, patient_df in\n",
    "                    rrms_df.groupby('gate_source')}\n",
    "nindc_df = df[df['diagnosis'] == 'NINDC']\n",
    "nindc_patients2df = {id: patient_df.drop(columns=['diagnosis', 'gate_source']) for id, patient_df in\n",
    "                     nindc_df.groupby('gate_source')}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### split by diagnosis state\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('RRMS cell-type abundances')\n",
    "rrms_df.groupby('cluster').count()\n",
    "print('Mean abundancy / patient is 273,032258065')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### to just see how many per diagnosis state are there.\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('NINDC cell-type abundances')\n",
    "nindc_df.groupby('cluster').count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "\n",
    "#### here we could see freq differences across the 2 groups\n",
    "print('Frequencies: ')\n",
    "rrms_patients_freq = {id: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list=True) for id, patient_df in\n",
    "                      rrms_patients2df.items()}\n",
    "nindc_patients_freq = {id: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list=True) for id, patient_df\n",
    "                       in nindc_patients2df.items()}\n",
    "print('DONE')\n",
    "# we got 31 patients each"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### celltype frequencies\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### To get true frequencies we need to get rid of 0 entries (there are patient without some cells type due to data)\n",
    "print('RRMS')\n",
    "rrms_freq_df = pd.DataFrame(list(rrms_patients_freq.values()), columns=list(cluster_to_celltype_dict.values()))\n",
    "rrms_freq_df = rrms_freq_df.replace(0, np.NaN)  ## this lets us skip the 0 entries\n",
    "rrms_freq_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('NINDC')\n",
    "nindc_freq_df = pd.DataFrame(list(nindc_patients_freq.values()), columns=list(cluster_to_celltype_dict.values()))\n",
    "nindc_freq_df = nindc_freq_df.replace(0, np.NaN)\n",
    "nindc_freq_df.describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#batch_sizes = [1,2,3,4,5,7,10]\n",
    "batch_sizes = [7]\n",
    "batch_size_dict_nkt = dict()\n",
    "cluster = 3\n",
    "for batch_size in batch_sizes:\n",
    "    ### desease states 1 = RRMS and 0 = NINDC\n",
    "    selection_pool_rrms_nkt, too_few_data_rrms_nkt = get_chunks_from_df(rrms_patients2df,\n",
    "                           freq_df=rrms_patients_freq,\n",
    "                           desease_state=1,\n",
    "                           cluster=cluster,\n",
    "                           batch_size=batch_size)\n",
    "    selection_pool_nindc_nkt, too_few_data_nindc_nkt = get_chunks_from_df(nindc_patients2df,\n",
    "                           freq_df=nindc_patients_freq,\n",
    "                           desease_state=0,\n",
    "                           cluster=cluster,\n",
    "                           batch_size=batch_size)\n",
    "    #todo make sure list are equally long:\n",
    "    if len(selection_pool_rrms_nkt) > len(selection_pool_nindc_nkt):\n",
    "        selection_pool_rrms_nkt = selection_pool_rrms_nkt[:len(selection_pool_nindc_nkt)]\n",
    "    elif len(selection_pool_rrms_nkt) < len(selection_pool_nindc_nkt):\n",
    "        selection_pool_nindc_nkt = selection_pool_nindc_nkt[:len(selection_pool_rrms_nkt)]\n",
    "\n",
    "    all_chunks = selection_pool_rrms_nkt + selection_pool_nindc_nkt\n",
    "    np.random.shuffle(all_chunks)\n",
    "\n",
    "    X = [selection[0] for selection in all_chunks]\n",
    "    nkt = [selection[1] for selection in all_chunks]\n",
    "    Y = [selection[2] for selection in all_chunks]\n",
    "    batch_size_dict_nkt[batch_size] = (X, nkt, Y)\n",
    "\n",
    "print('prep done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##### NKT trial reg\n",
    "model_container_nkt = []\n",
    "stats_dict_reg_nkt = dict()\n",
    "cluster=3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for batch_size, values in batch_size_dict_nkt.items():\n",
    "    # for regression task stratified is wrong since there are no classes\n",
    "    kf = KFold(n_splits=2, random_state=rand_seed, shuffle=True)\n",
    "    model_container = []\n",
    "    freq_idx =2\n",
    "    X, nkt = values[0], values[1]\n",
    "    nkt = [series[freq_idx] for series in nkt]\n",
    "    X_test, X_train, X_valid, nkt_test, nkt_train, nkt_valid = split_test_valid_train(\n",
    "        X=X,\n",
    "        y=nkt,\n",
    "        test_perc=test_perc,\n",
    "        train_perc=train_perc,\n",
    "        valid_perc=0.5, seed=rand_seed)\n",
    "    X = np.array([*X_train, *X_valid])\n",
    "    nkt = np.array([*nkt_train, *nkt_valid])\n",
    "    i = 1\n",
    "    for train_idx, valid_idx, in kf.split(X=X):\n",
    "        outdir_pheno_reg_nkt = f'ms_pheno_reg_nkt_{batch_size}_v2_{i}'\n",
    "        i = i +1\n",
    "        X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "        nkt_train, nkt_valid = nkt[train_idx], nkt[valid_idx]\n",
    "        model = get_fitted_model(X_train, X_valid, nkt_train, nkt_valid,\n",
    "                                 nsubset=1000,\n",
    "                                 nfilters=[3, 15, 25, 35], coeff_l1=0,\n",
    "                                 max_epochs=100, nrun=30, learning_rate=None,\n",
    "                                 ncell=batch_size,\n",
    "                                 per_sample=True, regression=True,\n",
    "                                 outdir=outdir_pheno_reg_nkt, verbose=False)\n",
    "        model_container_nkt.append(model)\n",
    "print('DONE NKT models built')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "outdir_nkt = 'nkt'\n",
    "stats_file = open(f\"{outdir_nkt}_stats_file.txt\", \"x+\")\n",
    "stats_file.write(f\"Batchsize: {batch_size}\")\n",
    "mses = []\n",
    "for model in model_container_nkt:\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "    #print_regression_model_stats(test_pred, b_test)\n",
    "    mse_test = mean_squared_error(nkt_test, test_pred)\n",
    "    mse_train = mean_squared_error(nkt_train, train_pred)\n",
    "    mse_valid = mean_squared_error(nkt_valid, valid_pred)\n",
    "    mses.append(mse_test)\n",
    "    stats_file.write(f'MSE test {mse_test}')\n",
    "    stats_file.write(f'MSE train {mse_train}')\n",
    "    stats_file.write(f'MSE valid {mse_valid}')\n",
    "    stats_file.write('\\n')\n",
    "mean_mse = float(sum(mses) / len(mses))\n",
    "stats_file.write(f\"Mean MSE: {str(mean_mse)}\")\n",
    "stats_dict_reg_nkt[batch_size] = {'mean_mse': mean_mse}\n",
    "stats_file.close()\n",
    "print('DONE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
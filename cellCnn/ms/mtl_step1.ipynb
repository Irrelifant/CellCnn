{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cellCnn\n",
    "import importlib\n",
    "importlib.reload(cellCnn)\n",
    "import random\n",
    "import numpy as np\n",
    "### (from: https://github.com/eiriniar/CellCnn/blob/0413a9f49fe0831c8fe3280957fb341f9e028d2d/cellCnn/examples/NK_cell_ungated.ipynb ) AND https://github.com/eiriniar/CellCnn/blob/0413a9f49fe0831c8fe3280957fb341f9e028d2d/cellCnn/examples/PBMC.ipynb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cellCnn.ms.utils.helpers import get_min_mean_from_clusters, get_chunks\n",
    "from cellCnn.utils import mkdir_p\n",
    "from cellCnn.plotting import plot_results\n",
    "from cellCnn.ms.utils.helpers import get_chunks\n",
    "from cellCnn.ms.utils.helpers import print_regression_model_stats\n",
    "from cellCnn.plotting import plot_results\n",
    "from cellCnn.utils import mkdir_p\n",
    "from cellCnn.utils import save_results\n",
    "from cellCnn.ms.utils.helpers import get_fitted_model\n",
    "from cellCnn.ms.utils.helpers import split_test_valid_train\n",
    "from cellCnn.ms.utils.helpers import calc_frequencies, get_chunks_from_df\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "##### state vars\n",
    "cytokines = ['CCR2', 'CCR4', 'CCR6', 'CCR7', 'CXCR4', 'CXCR5', 'CD103', 'CD14', 'CD20', 'CD25', 'CD27', 'CD28', 'CD3',\n",
    "             'CD4', 'CD45RA', 'CD45RO', 'CD56', 'CD57', 'CD69', 'CD8', 'TCRgd', 'PD.1', 'GM.CSF', 'IFN.g', 'IL.10',\n",
    "             'IL.13', 'IL.17A', 'IL.2', 'IL.21', 'IL.22', 'IL.3', 'IL.4', 'IL.6', 'IL.9', 'TNF.a']\n",
    "infile = 'cohort_denoised_clustered_diagnosis_patients.csv'\n",
    "indir = 'data/input.nosync'\n",
    "outdir = 'out_ms_default'\n",
    "rand_seed = 123\n",
    "train_perc = 0.7\n",
    "test_perc = 0.3\n",
    "batch_size_pheno = 840 # deprecated  # so a size of 8425 is about equally sized in batches\n",
    "batch_size_cd4 = 550  # deprecated #so a size of 550 gets me 16 batches for cd4\n",
    "## information from ms_data project\n",
    "cluster_to_celltype_dict = {0: 'b', 1: 'cd4', 3: 'nkt', 8: 'cd8', 10: 'nk', 11: 'my', 16: 'dg'}\n",
    "outfolder = 'mtl_1'\n",
    "mkdir_p(outfolder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(16889, 38)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(rand_seed)\n",
    "mkdir_p(outdir)\n",
    "df = pd.read_csv(os.path.join(indir, infile), index_col=0)\n",
    "df = df.drop_duplicates()  ### reduces overfitting at cost of fewer data\n",
    "df.shape\n",
    "##### no duplicates in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# pitch: key = gate_source, value = dict{diagnosis: df OR freq?}\n",
    "rrms_df = df[df['diagnosis'] == 'RRMS']\n",
    "rrms_patients2df = {id: patient_df.drop(columns=['diagnosis', 'gate_source']) for id, patient_df in\n",
    "                    rrms_df.groupby('gate_source')}\n",
    "nindc_df = df[df['diagnosis'] == 'NINDC']\n",
    "nindc_patients2df = {id: patient_df.drop(columns=['diagnosis', 'gate_source']) for id, patient_df in\n",
    "                     nindc_df.groupby('gate_source')}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### split by diagnosis state\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies: \n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "\n",
    "#### here we could see freq differences across the 2 groups\n",
    "print('Frequencies: ')\n",
    "rrms_patients_freq = {id: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list=True) for id, patient_df in\n",
    "                      rrms_patients2df.items()}\n",
    "nindc_patients_freq = {id: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list=True) for id, patient_df\n",
    "                       in nindc_patients2df.items()}\n",
    "print('DONE')\n",
    "# we got 31 patients each"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### celltype frequencies\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patients_clusters_conf_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m cluster \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m8\u001B[39m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# mean of clusters -> take minimum\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28mmin\u001B[39m \u001B[38;5;241m=\u001B[39m get_min_mean_from_clusters([cluster], cluster_to_celltype_dict, patients_clusters_conf_table)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#batch_sizes = [int(min*0.5),int(min*0.75),int(min*0.9),int(min), int(min*1.1), int(min*1.25)]\u001B[39;00m\n\u001B[1;32m      5\u001B[0m batch_sizes \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m0.9\u001B[39m)]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'patients_clusters_conf_table' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/5d38cf1d6tvdyny38zb_66540000gn/T/ipykernel_71980/562577321.py:4: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "data": {
      "text/plain": "cluster      0    1   3    8   10  11  16\ngate_source                              \n3.0          60  119   6   30   5   5   0\n4.0          15   46   0   45   2   1  13\n5.0          33  131   0   70   2   2   4\n8.0          24  122   0   31  10  11   4\n9.0          72  270   2  137  11  10   4\n...          ..  ...  ..  ...  ..  ..  ..\n128.0         4    6   4    6   1   6   0\n130.0        24   82   2   56   8   4   0\n131.0        20   48   2   14  13   7   0\n132.0         8   35   7   16   1   1  10\n133.0        26   48   3   37   8  12   6\n\n[62 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>cluster</th>\n      <th>0</th>\n      <th>1</th>\n      <th>3</th>\n      <th>8</th>\n      <th>10</th>\n      <th>11</th>\n      <th>16</th>\n    </tr>\n    <tr>\n      <th>gate_source</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3.0</th>\n      <td>60</td>\n      <td>119</td>\n      <td>6</td>\n      <td>30</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>15</td>\n      <td>46</td>\n      <td>0</td>\n      <td>45</td>\n      <td>2</td>\n      <td>1</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>33</td>\n      <td>131</td>\n      <td>0</td>\n      <td>70</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8.0</th>\n      <td>24</td>\n      <td>122</td>\n      <td>0</td>\n      <td>31</td>\n      <td>10</td>\n      <td>11</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>9.0</th>\n      <td>72</td>\n      <td>270</td>\n      <td>2</td>\n      <td>137</td>\n      <td>11</td>\n      <td>10</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>128.0</th>\n      <td>4</td>\n      <td>6</td>\n      <td>4</td>\n      <td>6</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>130.0</th>\n      <td>24</td>\n      <td>82</td>\n      <td>2</td>\n      <td>56</td>\n      <td>8</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>131.0</th>\n      <td>20</td>\n      <td>48</td>\n      <td>2</td>\n      <td>14</td>\n      <td>13</td>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>132.0</th>\n      <td>8</td>\n      <td>35</td>\n      <td>7</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>133.0</th>\n      <td>26</td>\n      <td>48</td>\n      <td>3</td>\n      <td>37</td>\n      <td>8</td>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>62 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "patients_clusters_conf_table = pd.crosstab(df['gate_source'], df['cluster'])\n",
    "sns.heatmap(patients_clusters_conf_table, annot=False, vmax=100)\n",
    "plt.show()\n",
    "#plt.savefig('images/patient_vs_cluster_conf_table.png')\n",
    "patients_clusters_conf_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD8 prep done\n"
     ]
    }
   ],
   "source": [
    "cluster = 8\n",
    "# mean of clusters -> take minimum\n",
    "min = get_min_mean_from_clusters([cluster], cluster_to_celltype_dict, patients_clusters_conf_table)\n",
    "#batch_sizes = [int(min*0.5),int(min*0.75),int(min*0.9),int(min), int(min*1.1), int(min*1.25)]\n",
    "batch_sizes = [int(min*0.9)]\n",
    "batch_size_dict_cd8 = dict()\n",
    "for batch_size in batch_sizes:\n",
    "    ### desease states 1 = RRMS and 0 = NINDC\n",
    "    selection_pool_rrms_cd8, too_few_data_rrms_cd8 = get_chunks_from_df(rrms_patients2df,\n",
    "                           freq_df=rrms_patients_freq,\n",
    "                           desease_state=1,\n",
    "                           cluster=cluster,\n",
    "                           batch_size=batch_size)\n",
    "    selection_pool_nindc_cd8, too_few_data_nindc_cd8 = get_chunks_from_df(nindc_patients2df,\n",
    "                           freq_df=nindc_patients_freq,\n",
    "                           desease_state=0,\n",
    "                           cluster=cluster,\n",
    "                           batch_size=batch_size)\n",
    "\n",
    "    # make sure list are equally long:\n",
    "    if len(selection_pool_rrms_cd8) > len(selection_pool_nindc_cd8):\n",
    "        selection_pool_rrms_cd8 = selection_pool_rrms_cd8[:len(selection_pool_nindc_cd8)]\n",
    "    elif len(selection_pool_rrms_cd8) < len(selection_pool_nindc_cd8):\n",
    "        selection_pool_nindc_cd8 = selection_pool_nindc_cd8[:len(selection_pool_rrms_cd8)]\n",
    "\n",
    "    all_chunks = selection_pool_rrms_cd8 + selection_pool_nindc_cd8\n",
    "    np.random.shuffle(all_chunks)\n",
    "\n",
    "    X = [selection[0] for selection in all_chunks]\n",
    "    cd8 = [selection[1] for selection in all_chunks]\n",
    "    Y = [selection[2] for selection in all_chunks]\n",
    "    batch_size_dict_cd8[batch_size] = (X, cd8, Y)\n",
    "\n",
    "print('CD8 prep done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### CD8 Freq regression task + MTL\n",
    "model_container_cd8 = []\n",
    "stats_dict_reg_cd8 = dict()\n",
    "outdir_cd8 = outfolder + 'test_1_cd8'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [23]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     31\u001B[0m         y_train, y_valid \u001B[38;5;241m=\u001B[39m y[train_idx], y[valid_idx]\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;66;03m# todo nsubset parameter maybe different\u001B[39;00m\n\u001B[0;32m---> 34\u001B[0m         model \u001B[38;5;241m=\u001B[39m get_fitted_model(X_train, X_valid, [y_train, cd8_train], [cd8_valid, y_valid],\n\u001B[1;32m     35\u001B[0m                                  nsubset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mint\u001B[39m(batch_size\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlen\u001B[39m(X_train)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m),\n\u001B[1;32m     36\u001B[0m                                  nfilters\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m35\u001B[39m], coeff_l1\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     37\u001B[0m                                  max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, nrun\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     38\u001B[0m                                  ncell\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m     39\u001B[0m                                  per_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, regression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     40\u001B[0m                                  outdir\u001B[38;5;241m=\u001B[39moutdir_pheno_reg_cd8, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, mtl_tasks\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     41\u001B[0m         model_container_cd8\u001B[38;5;241m.\u001B[39mappend(model)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDONE building models\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/ms/utils/helpers.py:175\u001B[0m, in \u001B[0;36mget_fitted_model\u001B[0;34m(X_train, X_valid, y_train, y_valid, nrun, ncell, nsubset, nfilters, coeff_l2, coeff_l1, max_epochs, learning_rate, outdir, per_sample, regression, verbose, result, mtl_tasks)\u001B[0m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;66;03m## parameters from PBMC example\u001B[39;00m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;66;03m###per_sample bei regression\u001B[39;00m\n\u001B[1;32m    169\u001B[0m model \u001B[38;5;241m=\u001B[39m CellCnn(nrun\u001B[38;5;241m=\u001B[39mnrun, ncell\u001B[38;5;241m=\u001B[39mncell, nsubset\u001B[38;5;241m=\u001B[39mnsubset,\n\u001B[1;32m    170\u001B[0m                 nfilter_choice\u001B[38;5;241m=\u001B[39mnfilters, learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate,\n\u001B[1;32m    171\u001B[0m                 coeff_l2\u001B[38;5;241m=\u001B[39mcoeff_l2, coeff_l1\u001B[38;5;241m=\u001B[39mcoeff_l1,\n\u001B[1;32m    172\u001B[0m                 max_epochs\u001B[38;5;241m=\u001B[39mmax_epochs, per_sample\u001B[38;5;241m=\u001B[39mper_sample,\n\u001B[1;32m    173\u001B[0m                 regression\u001B[38;5;241m=\u001B[39mregression, verbose\u001B[38;5;241m=\u001B[39mverbose, mtl_tasks\u001B[38;5;241m=\u001B[39mmtl_tasks)\n\u001B[0;32m--> 175\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_phenotypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mvalid_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_phenotypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_valid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m                  \u001B[49m\u001B[43moutdir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutdir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:159\u001B[0m, in \u001B[0;36mCellCnn.fit\u001B[0;34m(self, train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, train_samples, train_phenotypes, outdir, valid_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    123\u001B[0m         valid_phenotypes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, generate_valid_set\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;124;03m\"\"\" Trains a CellCnn model.\u001B[39;00m\n\u001B[1;32m    126\u001B[0m \n\u001B[1;32m    127\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;124;03m        - n_classes : number of output classes\u001B[39;00m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 159\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_phenotypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutdir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mvalid_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_phenotypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerate_valid_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mscale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnrun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnrun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mregression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mncell\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mncell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnsubset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnsubset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mper_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mper_sample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m                      \u001B[49m\u001B[43msubset_selection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubset_selection\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mmaxpool_percentages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaxpool_percentages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mnfilter_choice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnfilter_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mcoeff_l1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_l1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoeff_l2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_l2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatience\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdendrogram_cutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdendrogram_cutoff\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m                      \u001B[49m\u001B[43maccur_thres\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccur_thres\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmtl_tasks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmtl_tasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m res\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:351\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set, scale, quant_normed, nrun, regression, ncell, nsubset, per_sample, subset_selection, maxpool_percentages, nfilter_choice, learning_rate, coeff_l1, coeff_l2, dropout, dropout_p, max_epochs, patience, dendrogram_cutoff, accur_thres, verbose, mtl_tasks)\u001B[0m\n\u001B[1;32m    347\u001B[0m     train_phenotype_dict[task] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(train_phenotype_dict[task])\n\u001B[1;32m    349\u001B[0m \u001B[38;5;66;03m# an array containing the phenotype for each single cell\u001B[39;00m\n\u001B[1;32m    350\u001B[0m \u001B[38;5;66;03m# # todo check if i need y_train several times -> für outlier\u001B[39;00m\n\u001B[0;32m--> 351\u001B[0m y_train \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_phenotypes\u001B[49m\u001B[43m[\u001B[49m\u001B[43mid_train\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (valid_samples \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m generate_valid_set:\n\u001B[1;32m    354\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m scale:\n",
      "\u001B[0;31mTypeError\u001B[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "importlib.reload(cellCnn)\n",
    "importlib.reload(cellCnn.utils)\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "from cellCnn import *\n",
    "from cellCnn.utils import *\n",
    "\n",
    "kf_split = 2\n",
    "for batch_size, values, in batch_size_dict_cd8.items():\n",
    "    # for regression task stratified is wrong since there are no classes\n",
    "    kf = KFold(n_splits=kf_split, random_state=rand_seed, shuffle=True)\n",
    "    model_container = []\n",
    "    freq_idx =3\n",
    "    X, cd8, y = values[0], values[1], values[2]\n",
    "    cd8 = [series[freq_idx] for series in cd8]\n",
    "\n",
    "    X_test, X_train, X_valid, cd8_test, cd8_train, cd8_valid, y_test, y_train, y_valid = split_test_train_valid(\n",
    "        X, cd8, y,\n",
    "        train_perc=train_perc,\n",
    "        test_perc=test_perc,\n",
    "        valid_perc=0.5)\n",
    "    X = np.array([*X_train, *X_valid])\n",
    "    cd8 = np.array([*cd8_train, *cd8_valid])\n",
    "    y = np.array([*y_train, *y_valid])\n",
    "    i = 1\n",
    "    for train_idx, valid_idx, in kf.split(X=X):\n",
    "        outdir_pheno_reg_cd8= f'{outdir_cd8}/ms_pheno_reg_cd8_{batch_size}_{i}_stl'\n",
    "        i = i +1\n",
    "        X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "        cd8_train, cd8_valid = cd8[train_idx], cd8[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        # todo nsubset parameter maybe different\n",
    "        model = get_fitted_model(X_train, X_valid, [y_train, cd8_train], [cd8_valid, y_valid],\n",
    "                                 nsubset=int(batch_size*len(X_train)/2),\n",
    "                                 nfilters=[3, 15, 25, 35], coeff_l1=0,\n",
    "                                 max_epochs=100, nrun=30, learning_rate=None,\n",
    "                                 ncell=batch_size,\n",
    "                                 per_sample=True, regression=True,\n",
    "                                 outdir=outdir_pheno_reg_cd8, verbose=False, mtl_tasks=2)\n",
    "        model_container_cd8.append(model)\n",
    "print('DONE building models')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "importlib.reload(cellCnn.model)\n",
    "importlib.reload(cellCnn)\n",
    "importlib.reload(cellCnn.utils)\n",
    "from cellCnn.utils import *\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "from cellCnn import *\n",
    "\n",
    "stats_file = open(f\"{outdir_cd8}_stats_file_UncertaintyLoss.txt\", \"w+\")\n",
    "mses = []\n",
    "\n",
    "# what predict does is: Iterating over the best 3 nets and return an array per net with the predictions for all samples!\n",
    "bs_idx = 1\n",
    "for i, model in enumerate(model_container_cd8):\n",
    "    stats_file.write(f\"Model {i}; Batchsize: {batch_sizes[bs_idx-1]}\\n\")\n",
    "    if bs_idx % kf_split == 0: ## when the kf split amount is reaches the next batchsize is applied\n",
    "        bs_idx = bs_idx +1\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "    #print_regression_model_stats(test_pred, b_test)\n",
    "    mse_test = mean_squared_error(y_test, test_pred[0])\n",
    "    mse_train = mean_squared_error(y_train, train_pred[0])\n",
    "    mse_valid = mean_squared_error(y_valid, valid_pred[0])\n",
    "    mses.append(mse_test)\n",
    "\n",
    "    stats_file.write('Desease: \\n')\n",
    "    stats_file.write(f'MSE y test {mse_test}\\n')\n",
    "    stats_file.write(f'MSE y train {mse_train}\\n')\n",
    "    stats_file.write(f'MSE y valid {mse_valid}\\n')\n",
    "\n",
    "    mse_test_cd8 = mean_squared_error(cd8_test, test_pred[1])\n",
    "    mse_train_cd8 = mean_squared_error(cd8_train, train_pred[1])\n",
    "    mse_valid_cd8 = mean_squared_error(cd8_valid, valid_pred[1])\n",
    "    mses.append(mse_test_cd8)\n",
    "\n",
    "    stats_file.write('Cd8: \\n')\n",
    "    stats_file.write(f'MSE y test {mse_test_cd8}\\n')\n",
    "    stats_file.write(f'MSE y train {mse_train_cd8}\\n')\n",
    "    stats_file.write(f'MSE y valid {mse_valid_cd8}\\n')\n",
    "    stats_file.write('\\n')\n",
    "mean_mse = float(sum(mses) / len(mses))\n",
    "stats_file.write(f\"Mean MSE: {str(mean_mse)}\")\n",
    "stats_dict_reg_cd8[batch_size] = {'mean_mse': mean_mse}\n",
    "stats_file.close()\n",
    "print('DONE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cellCnn\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "### (from: https://github.com/eiriniar/CellCnn/blob/0413a9f49fe0831c8fe3280957fb341f9e028d2d/cellCnn/examples/NK_cell_ungated.ipynb ) AND https://github.com/eiriniar/CellCnn/blob/0413a9f49fe0831c8fe3280957fb341f9e028d2d/cellCnn/examples/PBMC.ipynb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cellCnn.ms.utils.helpers import get_min_mean_from_clusters, get_chunks\n",
    "from cellCnn.utils import mkdir_p\n",
    "from cellCnn.plotting import plot_results\n",
    "from cellCnn.ms.utils.helpers import get_chunks\n",
    "from cellCnn.ms.utils.helpers import print_regression_model_stats\n",
    "from cellCnn.plotting import plot_results\n",
    "from cellCnn.utils import mkdir_p\n",
    "from cellCnn.utils import save_results\n",
    "from cellCnn.ms.utils.helpers import get_fitted_model\n",
    "from cellCnn.ms.utils.helpers import split_test_valid_train\n",
    "from cellCnn.ms.utils.helpers import calc_frequencies, get_chunks_from_df\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "##### state vars\n",
    "cytokines = ['CCR2', 'CCR4', 'CCR6', 'CCR7', 'CXCR4', 'CXCR5', 'CD103', 'CD14', 'CD20', 'CD25', 'CD27', 'CD28', 'CD3',\n",
    "             'CD4', 'CD45RA', 'CD45RO', 'CD56', 'CD57', 'CD69', 'CD8', 'TCRgd', 'PD.1', 'GM.CSF', 'IFN.g', 'IL.10',\n",
    "             'IL.13', 'IL.17A', 'IL.2', 'IL.21', 'IL.22', 'IL.3', 'IL.4', 'IL.6', 'IL.9', 'TNF.a']\n",
    "infile = 'cohort_denoised_clustered_diagnosis_patients.csv'\n",
    "indir = 'data/input.nosync'\n",
    "outdir = 'out_ms_default'\n",
    "rand_seed = 123\n",
    "train_perc = 0.7\n",
    "test_perc = 0.3\n",
    "batch_size_pheno = 840 # deprecated  # so a size of 8425 is about equally sized in batches\n",
    "batch_size_cd4 = 550  # deprecated #so a size of 550 gets me 16 batches for cd4\n",
    "## information from ms_data project\n",
    "cluster_to_celltype_dict = {0: 'b', 1: 'cd4', 3: 'nkt', 8: 'cd8', 10: 'nk', 11: 'my', 16: 'dg'}\n",
    "outfolder = 'mtl_1'\n",
    "mkdir_p(outfolder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(16889, 38)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(rand_seed)\n",
    "mkdir_p(outdir)\n",
    "df = pd.read_csv(os.path.join(indir, infile), index_col=0)\n",
    "df = df.drop_duplicates()  ### reduces overfitting at cost of fewer data\n",
    "df.shape\n",
    "##### no duplicates in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# pitch: key = gate_source, value = dict{diagnosis: df OR freq?}\n",
    "rrms_df = df[df['diagnosis'] == 'RRMS']\n",
    "rrms_patients2df = {id: patient_df.drop(columns=['diagnosis', 'gate_source']) for id, patient_df in\n",
    "                    rrms_df.groupby('gate_source')}\n",
    "nindc_df = df[df['diagnosis'] == 'NINDC']\n",
    "nindc_patients2df = {id: patient_df.drop(columns=['diagnosis', 'gate_source']) for id, patient_df in\n",
    "                     nindc_df.groupby('gate_source')}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### split by diagnosis state\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies: \n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#### here we could see freq differences across the 2 groups\n",
    "print('Frequencies: ')\n",
    "rrms_patients_freq = {id: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list=True) for id, patient_df in\n",
    "                      rrms_patients2df.items()}\n",
    "nindc_patients_freq = {id: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list=True) for id, patient_df\n",
    "                       in nindc_patients2df.items()}\n",
    "print('DONE')\n",
    "# we got 31 patients each"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### celltype frequencies\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/5d38cf1d6tvdyny38zb_66540000gn/T/ipykernel_13083/1790410289.py:3: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "data": {
      "text/plain": "cluster      0    1   3    8   10  11  16\ngate_source                              \n3.0          60  119   6   30   5   5   0\n4.0          15   46   0   45   2   1  13\n5.0          33  131   0   70   2   2   4\n8.0          24  122   0   31  10  11   4\n9.0          72  270   2  137  11  10   4\n...          ..  ...  ..  ...  ..  ..  ..\n128.0         4    6   4    6   1   6   0\n130.0        24   82   2   56   8   4   0\n131.0        20   48   2   14  13   7   0\n132.0         8   35   7   16   1   1  10\n133.0        26   48   3   37   8  12   6\n\n[62 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>cluster</th>\n      <th>0</th>\n      <th>1</th>\n      <th>3</th>\n      <th>8</th>\n      <th>10</th>\n      <th>11</th>\n      <th>16</th>\n    </tr>\n    <tr>\n      <th>gate_source</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3.0</th>\n      <td>60</td>\n      <td>119</td>\n      <td>6</td>\n      <td>30</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>15</td>\n      <td>46</td>\n      <td>0</td>\n      <td>45</td>\n      <td>2</td>\n      <td>1</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>33</td>\n      <td>131</td>\n      <td>0</td>\n      <td>70</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8.0</th>\n      <td>24</td>\n      <td>122</td>\n      <td>0</td>\n      <td>31</td>\n      <td>10</td>\n      <td>11</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>9.0</th>\n      <td>72</td>\n      <td>270</td>\n      <td>2</td>\n      <td>137</td>\n      <td>11</td>\n      <td>10</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>128.0</th>\n      <td>4</td>\n      <td>6</td>\n      <td>4</td>\n      <td>6</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>130.0</th>\n      <td>24</td>\n      <td>82</td>\n      <td>2</td>\n      <td>56</td>\n      <td>8</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>131.0</th>\n      <td>20</td>\n      <td>48</td>\n      <td>2</td>\n      <td>14</td>\n      <td>13</td>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>132.0</th>\n      <td>8</td>\n      <td>35</td>\n      <td>7</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>133.0</th>\n      <td>26</td>\n      <td>48</td>\n      <td>3</td>\n      <td>37</td>\n      <td>8</td>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>62 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clusters_conf_table = pd.crosstab(df['gate_source'], df['cluster'])\n",
    "sns.heatmap(patients_clusters_conf_table, annot=False, vmax=100)\n",
    "plt.show()\n",
    "#plt.savefig('images/patient_vs_cluster_conf_table.png')\n",
    "patients_clusters_conf_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: batches created\n"
     ]
    }
   ],
   "source": [
    "# todo ich muss eigentlich die frequency pro batch berechnen...\n",
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "\n",
    "# batch_sizes = [40,80,120, 160]\n",
    "batch_size_dict = dict()\n",
    "batch_sizes = [120]\n",
    "for batch_size in batch_sizes:\n",
    "    ### desease states 1 = RRMS and 0 = NINDC\n",
    "    selection_pool_rrms_cd8 = get_chunks_from_df(rrms_patients2df,\n",
    "                           freq_df=rrms_patients_freq,\n",
    "                           desease_state=1,\n",
    "                           batch_size=batch_size)\n",
    "    selection_pool_nindc_cd8 = get_chunks_from_df(nindc_patients2df,\n",
    "                           freq_df=nindc_patients_freq,\n",
    "                           desease_state=0,\n",
    "                           batch_size=batch_size)\n",
    "\n",
    "    # make sure list are equally long:\n",
    "    if len(selection_pool_rrms_cd8) > len(selection_pool_nindc_cd8):\n",
    "        selection_pool_rrms_cd8 = selection_pool_rrms_cd8[:len(selection_pool_nindc_cd8)]\n",
    "    elif len(selection_pool_rrms_cd8) < len(selection_pool_nindc_cd8):\n",
    "        selection_pool_nindc_cd8 = selection_pool_nindc_cd8[:len(selection_pool_rrms_cd8)]\n",
    "\n",
    "    all_chunks = selection_pool_rrms_cd8 + selection_pool_nindc_cd8\n",
    "    np.random.shuffle(all_chunks)\n",
    "\n",
    "    X = [selection[0] for selection in all_chunks]\n",
    "    freqs = [selection[1] for selection in all_chunks]\n",
    "    Y = [selection[2] for selection in all_chunks]\n",
    "    batch_size_dict[batch_size] = (X, freqs, Y)\n",
    "\n",
    "print('DONE: batches created')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### Also ich brauch nicht mehr nach cell types in den batches suchen, es ist recht egal.\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "### CD8 Freq regression task + MTL\n",
    "model_container_cd8 = []\n",
    "stats_dict_reg_cd8 = dict()\n",
    "outdir_cd8 = 'mtl/class/cd8'\n",
    "mkdir_p(outdir_cd8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build called\n",
      "CALLING...\n",
      "[<tf.Tensor 'Placeholder:0' shape=(None, 2) dtype=float32>, <tf.Tensor 'Placeholder_1:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'Placeholder_2:0' shape=(None, 2) dtype=float32>, <tf.Tensor 'Placeholder_3:0' shape=(None, 1) dtype=float32>]\n",
      "Sigmas\n",
      "ListWrapper([array([0.39360324], dtype=float32), array([0.7090775], dtype=float32)])\n",
      "in mtl: split inputs\n",
      "mtl loss end\n",
      "Tensor(\"revised_uncertainty_loss_8/Min_1:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"revised_uncertainty_loss_8/Min_1:0\", shape=(), dtype=float32)\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data_input (InputLayer)        [(None, 200, 35)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1 (Conv1D)                 (None, 200, 25)      900         ['data_input[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)              (None, 25)           0           ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 25)           0           ['lambda_8[0][0]']               \n",
      "                                                                                                  \n",
      " input_desease (InputLayer)     [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_task_1 (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " output_desease (Dense)         (None, 2)            52          ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " output_freq_1 (Dense)          (None, 1)            26          ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " revised_uncertainty_loss_8 (Re  [(None, 2),         2           ['input_desease[0][0]',          \n",
      " visedUncertaintyLoss)           (None, 1)]                       'input_task_1[0][0]',           \n",
      "                                                                  'output_desease[0][0]',         \n",
      "                                                                  'output_freq_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 980\n",
      "Trainable params: 980\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Trainfit incoming\n",
      "CALLING...\n",
      "[<tf.Tensor 'IteratorGetNext:1' shape=(200, 2) dtype=float32>, <tf.Tensor 'model_6/ExpandDims:0' shape=(200, 1) dtype=float32>, <tf.Tensor 'model_6/output_desease/Softmax:0' shape=(200, 2) dtype=float32>, <tf.Tensor 'model_6/output_freq_1/BiasAdd:0' shape=(200, 1) dtype=float32>]\n",
      "Sigmas\n",
      "ListWrapper([array([0.39360324], dtype=float32), array([0.7090775], dtype=float32)])\n",
      "in mtl: split inputs\n",
      "mtl loss end\n",
      "Tensor(\"model_6/revised_uncertainty_loss_8/Min_1:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"model_6/revised_uncertainty_loss_8/Min_1:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['revised_uncertainty_loss_8/sigmas_sq_0:0', 'revised_uncertainty_loss_8/sigmas_sq_1:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "CALLING...\n",
      "[<tf.Tensor 'IteratorGetNext:1' shape=(200, 2) dtype=float32>, <tf.Tensor 'model_6/ExpandDims:0' shape=(200, 1) dtype=float32>, <tf.Tensor 'model_6/output_desease/Softmax:0' shape=(200, 2) dtype=float32>, <tf.Tensor 'model_6/output_freq_1/BiasAdd:0' shape=(200, 1) dtype=float32>]\n",
      "Sigmas\n",
      "ListWrapper([array([0.39360324], dtype=float32), array([0.7090775], dtype=float32)])\n",
      "in mtl: split inputs\n",
      "mtl loss end\n",
      "Tensor(\"model_6/revised_uncertainty_loss_8/Min_1:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"model_6/revised_uncertainty_loss_8/Min_1:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['revised_uncertainty_loss_8/sigmas_sq_0:0', 'revised_uncertainty_loss_8/sigmas_sq_1:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "CALLING...\n",
      "[<tf.Tensor 'IteratorGetNext:1' shape=(None, 2) dtype=float32>, <tf.Tensor 'model_6/ExpandDims:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'model_6/output_desease/Softmax:0' shape=(None, 2) dtype=float32>, <tf.Tensor 'model_6/output_freq_1/BiasAdd:0' shape=(None, 1) dtype=float32>]\n",
      "Sigmas\n",
      "ListWrapper([array([0.39360324], dtype=float32), array([0.7090775], dtype=float32)])\n",
      "in mtl: split inputs\n",
      "mtl loss end\n",
      "Tensor(\"model_6/revised_uncertainty_loss_8/Min_1:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"model_6/revised_uncertainty_loss_8/Min_1:0\", shape=(), dtype=float32)\n",
      "Trainfit done\n",
      "29/29 [==============================] - 0s 3ms/step - loss: -0.3227 - revised_uncertainty_loss_8_accuracy: 0.6333 - revised_uncertainty_loss_8_mean_squared_error: 0.2274 - revised_uncertainty_loss_8_1_accuracy: 0.7778 - revised_uncertainty_loss_8_1_mean_squared_error: 0.1838\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Build called\n",
      "CALLING...\n",
      "[<tf.Tensor 'Placeholder:0' shape=(None, 2) dtype=float32>, <tf.Tensor 'Placeholder_1:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'Placeholder_2:0' shape=(None, 2) dtype=float32>, <tf.Tensor 'Placeholder_3:0' shape=(None, 1) dtype=float32>]\n",
      "Sigmas\n",
      "ListWrapper([array([0.7166626], dtype=float32), array([0.43318453], dtype=float32)])\n",
      "in mtl: split inputs\n",
      "mtl loss end\n",
      "Tensor(\"revised_uncertainty_loss_9/Min_1:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"revised_uncertainty_loss_9/Min_1:0\", shape=(), dtype=float32)\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data_input (InputLayer)        [(None, 200, 35)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1 (Conv1D)                 (None, 200, 3)       108         ['data_input[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_9 (Lambda)              (None, 3)            0           ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 3)            0           ['lambda_9[0][0]']               \n",
      "                                                                                                  \n",
      " input_desease (InputLayer)     [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_task_1 (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " output_desease (Dense)         (None, 2)            8           ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " output_freq_1 (Dense)          (None, 1)            4           ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " revised_uncertainty_loss_9 (Re  [(None, 2),         2           ['input_desease[0][0]',          \n",
      " visedUncertaintyLoss)           (None, 1)]                       'input_task_1[0][0]',           \n",
      "                                                                  'output_desease[0][0]',         \n",
      "                                                                  'output_freq_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Trainfit incoming\n",
      "CALLING...\n",
      "[<tf.Tensor 'IteratorGetNext:1' shape=(200, 2) dtype=float32>, <tf.Tensor 'model_7/ExpandDims:0' shape=(200, 1) dtype=float32>, <tf.Tensor 'model_7/output_desease/Softmax:0' shape=(200, 2) dtype=float32>, <tf.Tensor 'model_7/output_freq_1/BiasAdd:0' shape=(200, 1) dtype=float32>]\n",
      "Sigmas\n",
      "ListWrapper([array([0.7166626], dtype=float32), array([0.43318453], dtype=float32)])\n",
      "in mtl: split inputs\n",
      "mtl loss end\n",
      "Tensor(\"model_7/revised_uncertainty_loss_9/Min_1:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"model_7/revised_uncertainty_loss_9/Min_1:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['revised_uncertainty_loss_9/sigmas_sq_0:0', 'revised_uncertainty_loss_9/sigmas_sq_1:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "CALLING...\n",
      "[<tf.Tensor 'IteratorGetNext:1' shape=(200, 2) dtype=float32>, <tf.Tensor 'model_7/ExpandDims:0' shape=(200, 1) dtype=float32>, <tf.Tensor 'model_7/output_desease/Softmax:0' shape=(200, 2) dtype=float32>, <tf.Tensor 'model_7/output_freq_1/BiasAdd:0' shape=(200, 1) dtype=float32>]\n",
      "Sigmas\n",
      "ListWrapper([array([0.7166626], dtype=float32), array([0.43318453], dtype=float32)])\n",
      "in mtl: split inputs\n",
      "mtl loss end\n",
      "Tensor(\"model_7/revised_uncertainty_loss_9/Min_1:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"model_7/revised_uncertainty_loss_9/Min_1:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['revised_uncertainty_loss_9/sigmas_sq_0:0', 'revised_uncertainty_loss_9/sigmas_sq_1:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "CALLING...\n",
      "[<tf.Tensor 'IteratorGetNext:1' shape=(None, 2) dtype=float32>, <tf.Tensor 'model_7/ExpandDims:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'model_7/output_desease/Softmax:0' shape=(None, 2) dtype=float32>, <tf.Tensor 'model_7/output_freq_1/BiasAdd:0' shape=(None, 1) dtype=float32>]\n",
      "Sigmas\n",
      "ListWrapper([array([0.7166626], dtype=float32), array([0.43318453], dtype=float32)])\n",
      "in mtl: split inputs\n",
      "mtl loss end\n",
      "Tensor(\"model_7/revised_uncertainty_loss_9/Min_1:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"model_7/revised_uncertainty_loss_9/Min_1:0\", shape=(), dtype=float32)\n",
      "Trainfit done\n",
      "29/29 [==============================] - 0s 2ms/step - loss: -0.4762 - revised_uncertainty_loss_9_accuracy: 1.0000 - revised_uncertainty_loss_9_mean_squared_error: 0.2391 - revised_uncertainty_loss_9_1_accuracy: 0.7778 - revised_uncertainty_loss_9_1_mean_squared_error: 0.1890\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Build called\n",
      "CALLING...\n",
      "[<tf.Tensor 'Placeholder:0' shape=(None, 2) dtype=float32>, <tf.Tensor 'Placeholder_1:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'Placeholder_2:0' shape=(None, 2) dtype=float32>, <tf.Tensor 'Placeholder_3:0' shape=(None, 1) dtype=float32>]\n",
      "Sigmas\n",
      "ListWrapper([array([0.31086332], dtype=float32), array([0.58361626], dtype=float32)])\n",
      "in mtl: split inputs\n",
      "mtl loss end\n",
      "Tensor(\"revised_uncertainty_loss_10/Min_1:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"revised_uncertainty_loss_10/Min_1:0\", shape=(), dtype=float32)\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data_input (InputLayer)        [(None, 200, 35)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1 (Conv1D)                 (None, 200, 25)      900         ['data_input[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_10 (Lambda)             (None, 25)           0           ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 25)           0           ['lambda_10[0][0]']              \n",
      "                                                                                                  \n",
      " input_desease (InputLayer)     [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_task_1 (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " output_desease (Dense)         (None, 2)            52          ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " output_freq_1 (Dense)          (None, 1)            26          ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " revised_uncertainty_loss_10 (R  [(None, 2),         2           ['input_desease[0][0]',          \n",
      " evisedUncertaintyLoss)          (None, 1)]                       'input_task_1[0][0]',           \n",
      "                                                                  'output_desease[0][0]',         \n",
      "                                                                  'output_freq_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 980\n",
      "Trainable params: 980\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Trainfit incoming\n",
      "CALLING...\n",
      "[<tf.Tensor 'IteratorGetNext:1' shape=(200, 2) dtype=float32>, <tf.Tensor 'model_8/ExpandDims:0' shape=(200, 1) dtype=float32>, <tf.Tensor 'model_8/output_desease/Softmax:0' shape=(200, 2) dtype=float32>, <tf.Tensor 'model_8/output_freq_1/BiasAdd:0' shape=(200, 1) dtype=float32>]\n",
      "Sigmas\n",
      "ListWrapper([array([0.31086332], dtype=float32), array([0.58361626], dtype=float32)])\n",
      "in mtl: split inputs\n",
      "mtl loss end\n",
      "Tensor(\"model_8/revised_uncertainty_loss_10/Min_1:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"model_8/revised_uncertainty_loss_10/Min_1:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['revised_uncertainty_loss_10/sigmas_sq_0:0', 'revised_uncertainty_loss_10/sigmas_sq_1:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "CALLING...\n",
      "[<tf.Tensor 'IteratorGetNext:1' shape=(200, 2) dtype=float32>, <tf.Tensor 'model_8/ExpandDims:0' shape=(200, 1) dtype=float32>, <tf.Tensor 'model_8/output_desease/Softmax:0' shape=(200, 2) dtype=float32>, <tf.Tensor 'model_8/output_freq_1/BiasAdd:0' shape=(200, 1) dtype=float32>]\n",
      "Sigmas\n",
      "ListWrapper([array([0.31086332], dtype=float32), array([0.58361626], dtype=float32)])\n",
      "in mtl: split inputs\n",
      "mtl loss end\n",
      "Tensor(\"model_8/revised_uncertainty_loss_10/Min_1:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"model_8/revised_uncertainty_loss_10/Min_1:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['revised_uncertainty_loss_10/sigmas_sq_0:0', 'revised_uncertainty_loss_10/sigmas_sq_1:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "CALLING...\n",
      "[<tf.Tensor 'IteratorGetNext:1' shape=(None, 2) dtype=float32>, <tf.Tensor 'model_8/ExpandDims:0' shape=(None, 1) dtype=float32>, <tf.Tensor 'model_8/output_desease/Softmax:0' shape=(None, 2) dtype=float32>, <tf.Tensor 'model_8/output_freq_1/BiasAdd:0' shape=(None, 1) dtype=float32>]\n",
      "Sigmas\n",
      "ListWrapper([array([0.31086332], dtype=float32), array([0.58361626], dtype=float32)])\n",
      "in mtl: split inputs\n",
      "mtl loss end\n",
      "Tensor(\"model_8/revised_uncertainty_loss_10/Min_1:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"model_8/revised_uncertainty_loss_10/Min_1:0\", shape=(), dtype=float32)\n",
      "Trainfit done\n",
      "29/29 [==============================] - 0s 6ms/step - loss: -0.3313 - revised_uncertainty_loss_10_accuracy: 0.5689 - revised_uncertainty_loss_10_mean_squared_error: 0.2786 - revised_uncertainty_loss_10_1_accuracy: 0.7778 - revised_uncertainty_loss_10_1_mean_squared_error: 0.1849\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "DONE building models\n",
      "DONE class with per_sampel true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport cellCnn\n",
    "from cellCnn import loss\n",
    "from cellCnn.loss import *\n",
    "import cellCnn\n",
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "importlib.reload(cellCnn.model)\n",
    "importlib.reload(cellCnn.loss)\n",
    "importlib.reload(cellCnn.utils)\n",
    "importlib.reload(cellCnn)\n",
    "from cellCnn.loss import *\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "import cellCnn\n",
    "from cellCnn.loss import RevisedUncertaintyLoss\n",
    "\n",
    "kf_split = 2\n",
    "for batch_size, values, in batch_size_dict.items():\n",
    "    # for regression task stratified is wrong since there are no classes\n",
    "    freq_idx =3\n",
    "    X, cd8, y = values[0], values[1], values[2]\n",
    "    cd8 = [series[freq_idx] for series in cd8]\n",
    "\n",
    "    X_test, X_train, X_valid, cd8_test, cd8_train, cd8_valid, y_test, y_train, y_valid = split_test_train_valid(\n",
    "        X, cd8, y,\n",
    "        train_perc=train_perc,\n",
    "        test_perc=test_perc,\n",
    "        valid_perc=0.5)\n",
    "    outdir_pheno_reg_cd8 = f'{outdir_cd8}/models/ms_class_cd8_{batch_size}'\n",
    "\n",
    "    # todo nsubset parameter maybe different\n",
    "    model = get_fitted_model(X_train, X_valid, [y_train, cd8_train], [cd8_valid, y_valid],\n",
    "                             nsubset=100,\n",
    "                             nfilters=[3, 15, 25, 35], coeff_l1=0,\n",
    "                             max_epochs=100, nrun=3, learning_rate=None,\n",
    "                             ncell=200,\n",
    "                             per_sample=True, regression=False,\n",
    "                             outdir='test', verbose=False, mtl_tasks=2)\n",
    "    model_container_cd8.append(model)\n",
    "print('DONE building models')\n",
    "print('DONE class with per_sampel true')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "accs = []\n",
    "\n",
    "# what predict does is: Iterating over the best 3 nets and return an array per net with the predictions for all samples!\n",
    "bs_idx = 1\n",
    "for i, model in enumerate(model_container_cd8):\n",
    "    stats_file = open(f\"{outdir_cd8}/stats_class_{model.ncell}_{model.nsubset}.txt\", \"w+\")\n",
    "    stats_file.write(f\"Model {i}; Batchsize: {batch_sizes[bs_idx-1]}\\n\")\n",
    "    if bs_idx % kf_split == 0: ## when the kf split amount is reaches the next batchsize is applied\n",
    "        bs_idx = bs_idx +1\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "    #print_regression_model_stats(test_pred, b_test)\n",
    "    test_pred_abs = [1 if pred[0]>pred[1] else 0 for pred in test_pred[0]]\n",
    "    train_pred_abs = [1 if pred[0]>pred[1] else 0 for pred in train_pred[0]]\n",
    "    valid_pred_abs = [1 if pred[0]>pred[1] else 0 for pred in valid_pred[0]]\n",
    "    acc_test = accuracy_score(y_test,  test_pred_abs)\n",
    "    acc_train = accuracy_score(y_train,  train_pred_abs)\n",
    "    acc_valid = accuracy_score(y_valid,  valid_pred_abs)\n",
    "    accs.append(acc_test)\n",
    "\n",
    "    stats_file.write('Desease: \\n')\n",
    "    stats_file.write(f'Acc y test {acc_test}\\n')\n",
    "    stats_file.write(f'Acc y train {acc_train}\\n')\n",
    "    stats_file.write(f'Acc y valid {acc_valid}\\n')\n",
    "\n",
    "    mse_test_cd8 = mean_squared_error(cd8_test, test_pred[1])\n",
    "    mse_train_cd8 = mean_squared_error(cd8_train, train_pred[1])\n",
    "    mse_valid_cd8 = mean_squared_error(cd8_valid, valid_pred[1])\n",
    "    mses.append(mse_test_cd8)\n",
    "\n",
    "    stats_file.write('Cd8: \\n')\n",
    "    stats_file.write(f'MSE y test {mse_test_cd8}\\n')\n",
    "    stats_file.write(f'MSE y train {mse_train_cd8}\\n')\n",
    "    stats_file.write(f'MSE y valid {mse_valid_cd8}\\n')\n",
    "    stats_file.write('\\n')\n",
    "    stats_file.close()\n",
    "print('DONE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "### CD8 Freq regression task + MTL\n",
    "model_container_cd8_class = []\n",
    "stats_dict_cd8_class = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build called\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret initializer identifier: <tf.Variable 'revised_uncertainty_loss_56/sigmas_sq_0:0' shape=() dtype=float32, numpy=0.0>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [31]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     22\u001B[0m     outdir_pheno_reg_cd8 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutdir_cd8\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/models/ms_class_cd8_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatch_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_psFalse\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;66;03m# todo nsubset parameter maybe different\u001B[39;00m\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;66;03m# yet you need to put phenotype data in frist place\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m     model \u001B[38;5;241m=\u001B[39m get_fitted_model(X_train, X_valid, [y_train, cd8_train], [y_valid, cd8_valid],\n\u001B[1;32m     27\u001B[0m                              nsubset\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[1;32m     28\u001B[0m                              nfilters\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m35\u001B[39m], coeff_l1\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     29\u001B[0m                              max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, nrun\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     30\u001B[0m                              ncell\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m,\n\u001B[1;32m     31\u001B[0m                              per_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, regression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     32\u001B[0m                              outdir\u001B[38;5;241m=\u001B[39moutdir_pheno_reg_cd8, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, mtl_tasks\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     33\u001B[0m     model_container_cd8_class\u001B[38;5;241m.\u001B[39mappend(model)\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDONE building models\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/ms/utils/helpers.py:169\u001B[0m, in \u001B[0;36mget_fitted_model\u001B[0;34m(X_train, X_valid, y_train, y_valid, nrun, ncell, nsubset, nfilters, coeff_l2, coeff_l1, max_epochs, learning_rate, outdir, subset_selection, per_sample, regression, verbose, result, mtl_tasks)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;66;03m## parameters from PBMC example\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;66;03m###per_sample bei regression\u001B[39;00m\n\u001B[1;32m    163\u001B[0m model \u001B[38;5;241m=\u001B[39m CellCnn(nrun\u001B[38;5;241m=\u001B[39mnrun, ncell\u001B[38;5;241m=\u001B[39mncell, nsubset\u001B[38;5;241m=\u001B[39mnsubset,\n\u001B[1;32m    164\u001B[0m                 nfilter_choice\u001B[38;5;241m=\u001B[39mnfilters, learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate,\n\u001B[1;32m    165\u001B[0m                 coeff_l2\u001B[38;5;241m=\u001B[39mcoeff_l2, coeff_l1\u001B[38;5;241m=\u001B[39mcoeff_l1, subset_selection\u001B[38;5;241m=\u001B[39msubset_selection,\n\u001B[1;32m    166\u001B[0m                 max_epochs\u001B[38;5;241m=\u001B[39mmax_epochs, per_sample\u001B[38;5;241m=\u001B[39mper_sample,\n\u001B[1;32m    167\u001B[0m                 regression\u001B[38;5;241m=\u001B[39mregression, verbose\u001B[38;5;241m=\u001B[39mverbose, mtl_tasks\u001B[38;5;241m=\u001B[39mmtl_tasks)\n\u001B[0;32m--> 169\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_phenotypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mvalid_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_phenotypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_valid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m                  \u001B[49m\u001B[43moutdir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutdir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:163\u001B[0m, in \u001B[0;36mCellCnn.fit\u001B[0;34m(self, train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, train_samples, train_phenotypes, outdir, valid_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    127\u001B[0m         valid_phenotypes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, generate_valid_set\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;124;03m\"\"\" Trains a CellCnn model.\u001B[39;00m\n\u001B[1;32m    130\u001B[0m \n\u001B[1;32m    131\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;124;03m        - n_classes : number of output classes\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 163\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_phenotypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutdir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mvalid_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_phenotypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerate_valid_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mscale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnrun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnrun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mregression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mncell\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mncell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnsubset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnsubset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mper_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mper_sample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m                      \u001B[49m\u001B[43msubset_selection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubset_selection\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mmaxpool_percentages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaxpool_percentages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mnfilter_choice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnfilter_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mcoeff_l1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_l1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoeff_l2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_l2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatience\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdendrogram_cutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdendrogram_cutoff\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m                      \u001B[49m\u001B[43maccur_thres\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccur_thres\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmtl_tasks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmtl_tasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m res\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:500\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set, scale, quant_normed, nrun, regression, ncell, nsubset, per_sample, subset_selection, maxpool_percentages, nfilter_choice, learning_rate, coeff_l1, coeff_l2, dropout, dropout_p, max_epochs, patience, dendrogram_cutoff, accur_thres, verbose, mtl_tasks)\u001B[0m\n\u001B[1;32m    497\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCells pooled: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    499\u001B[0m \u001B[38;5;66;03m# build the neural network\u001B[39;00m\n\u001B[0;32m--> 500\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mncell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnmark\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnfilter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mcoeff_l1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoeff_l2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout_p\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mregression\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_classes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmtl_tasks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmtl_tasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    503\u001B[0m statspath\u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(outdir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstats\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    504\u001B[0m keras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mplot_model(model, statspath, show_shapes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:729\u001B[0m, in \u001B[0;36mbuild_model\u001B[0;34m(ncell, nmark, nfilter, coeff_l1, coeff_l2, k, dropout, dropout_p, regression, n_classes, lr, mtl_tasks)\u001B[0m\n\u001B[1;32m    725\u001B[0m     y_task_inputs[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtask_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m layers\u001B[38;5;241m.\u001B[39mInput(shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m,), name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_task_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    727\u001B[0m \u001B[38;5;66;03m# dynamically defining the inputs, the user needs to insert as many as tasks (obviously...)\u001B[39;00m\n\u001B[1;32m    728\u001B[0m \u001B[38;5;66;03m# todo is there any solution that solves this better (by taking the y_trainÂ´Â´ as those )\u001B[39;00m\n\u001B[0;32m--> 729\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mRevisedUncertaintyLoss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlosses\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43my_pheno\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43my_task_inputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moutput_layers\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    730\u001B[0m \u001B[38;5;66;03m# evtl pooled statt output layers ?\u001B[39;00m\n\u001B[1;32m    731\u001B[0m model \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mModel(inputs\u001B[38;5;241m=\u001B[39m[data_input, y_pheno, \u001B[38;5;241m*\u001B[39my_task_inputs\u001B[38;5;241m.\u001B[39mvalues()], outputs\u001B[38;5;241m=\u001B[39mout)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/loss.py:21\u001B[0m, in \u001B[0;36mRevisedUncertaintyLoss.build\u001B[0;34m(self, input_shape)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_list)):\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;66;03m# random_uniform ?? initial var\u001B[39;00m\n\u001B[1;32m     19\u001B[0m     var \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39mvariable(value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     20\u001B[0m                                     constraint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m t: tf\u001B[38;5;241m.\u001B[39mclip_by_value(t, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m), name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msigmas_sq_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msigmas_sq \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_weight\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlog_var\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minitializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m]\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# self.sigmas_sq = np.array(sigma_list)\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_list) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msigmas_sq)\n",
      "\u001B[0;31mValueError\u001B[0m: Could not interpret initializer identifier: <tf.Variable 'revised_uncertainty_loss_56/sigmas_sq_0:0' shape=() dtype=float32, numpy=0.0>"
     ]
    }
   ],
   "source": [
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "importlib.reload(cellCnn.model)\n",
    "importlib.reload(cellCnn)\n",
    "importlib.reload(cellCnn.utils)\n",
    "from cellCnn.utils import *\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "from cellCnn import *\n",
    "\n",
    "\n",
    "kf_split = 2\n",
    "for batch_size, values, in batch_size_dict.items():\n",
    "    # for regression task stratified is wrong since there are no classes\n",
    "    freq_idx =3\n",
    "    X, cd8, y = values[0], values[1], values[2]\n",
    "    cd8 = [series[freq_idx] for series in cd8]\n",
    "\n",
    "    X_test, X_train, X_valid, cd8_test, cd8_train, cd8_valid, y_test, y_train, y_valid = split_test_train_valid(\n",
    "        X, cd8, y,\n",
    "        train_perc=train_perc,\n",
    "        test_perc=test_perc,\n",
    "        valid_perc=0.5)\n",
    "    outdir_pheno_reg_cd8 = f'{outdir_cd8}/models/ms_class_cd8_{batch_size}_psFalse'\n",
    "\n",
    "    # todo nsubset parameter maybe different\n",
    "    # yet you need to put phenotype data in frist place\n",
    "    model = get_fitted_model(X_train, X_valid, [y_train, cd8_train], [y_valid, cd8_valid],\n",
    "                             nsubset=100,\n",
    "                             nfilters=[3, 15, 25, 35], coeff_l1=0,\n",
    "                             max_epochs=100, nrun=10, learning_rate=None,\n",
    "                             ncell=200,\n",
    "                             per_sample=False, regression=False,\n",
    "                             outdir=outdir_pheno_reg_cd8, verbose=False, mtl_tasks=2)\n",
    "    model_container_cd8_class.append(model)\n",
    "print('DONE building models')\n",
    "print('DONE class with per_sampel false')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### Bughunter: stl to compare\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "uncertainty_loss() missing 1 required positional argument: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     23\u001B[0m     outdir_pheno_reg_cd8 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutdir_cd8\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/models/ms_class_cd8_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatch_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_psFalse\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;66;03m# todo nsubset parameter maybe different\u001B[39;00m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;66;03m# yet you need to put phenotype data in frist place\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m     model \u001B[38;5;241m=\u001B[39m get_fitted_model(X_train, X_valid, y_train, y_valid,\n\u001B[1;32m     28\u001B[0m                              nsubset\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[1;32m     29\u001B[0m                              nfilters\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m35\u001B[39m], coeff_l1\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     30\u001B[0m                              max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, nrun\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     31\u001B[0m                              ncell\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m,\n\u001B[1;32m     32\u001B[0m                              per_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, regression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     33\u001B[0m                              outdir\u001B[38;5;241m=\u001B[39moutdir_pheno_reg_cd8, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, mtl_tasks\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     34\u001B[0m     model_container_cd8_2\u001B[38;5;241m.\u001B[39mappend(model)\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDONE building models\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/ms/utils/helpers.py:169\u001B[0m, in \u001B[0;36mget_fitted_model\u001B[0;34m(X_train, X_valid, y_train, y_valid, nrun, ncell, nsubset, nfilters, coeff_l2, coeff_l1, max_epochs, learning_rate, outdir, subset_selection, per_sample, regression, verbose, result, mtl_tasks)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;66;03m## parameters from PBMC example\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;66;03m###per_sample bei regression\u001B[39;00m\n\u001B[1;32m    163\u001B[0m model \u001B[38;5;241m=\u001B[39m CellCnn(nrun\u001B[38;5;241m=\u001B[39mnrun, ncell\u001B[38;5;241m=\u001B[39mncell, nsubset\u001B[38;5;241m=\u001B[39mnsubset,\n\u001B[1;32m    164\u001B[0m                 nfilter_choice\u001B[38;5;241m=\u001B[39mnfilters, learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate,\n\u001B[1;32m    165\u001B[0m                 coeff_l2\u001B[38;5;241m=\u001B[39mcoeff_l2, coeff_l1\u001B[38;5;241m=\u001B[39mcoeff_l1, subset_selection\u001B[38;5;241m=\u001B[39msubset_selection,\n\u001B[1;32m    166\u001B[0m                 max_epochs\u001B[38;5;241m=\u001B[39mmax_epochs, per_sample\u001B[38;5;241m=\u001B[39mper_sample,\n\u001B[1;32m    167\u001B[0m                 regression\u001B[38;5;241m=\u001B[39mregression, verbose\u001B[38;5;241m=\u001B[39mverbose, mtl_tasks\u001B[38;5;241m=\u001B[39mmtl_tasks)\n\u001B[0;32m--> 169\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_phenotypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mvalid_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_phenotypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_valid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m                  \u001B[49m\u001B[43moutdir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutdir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:162\u001B[0m, in \u001B[0;36mCellCnn.fit\u001B[0;34m(self, train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, train_samples, train_phenotypes, outdir, valid_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    126\u001B[0m         valid_phenotypes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, generate_valid_set\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;124;03m\"\"\" Trains a CellCnn model.\u001B[39;00m\n\u001B[1;32m    129\u001B[0m \n\u001B[1;32m    130\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;124;03m        - n_classes : number of output classes\u001B[39;00m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 162\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_phenotypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutdir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mvalid_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_phenotypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerate_valid_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mscale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnrun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnrun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mregression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mncell\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mncell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnsubset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnsubset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mper_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mper_sample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m                      \u001B[49m\u001B[43msubset_selection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubset_selection\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mmaxpool_percentages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaxpool_percentages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mnfilter_choice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnfilter_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mcoeff_l1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_l1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoeff_l2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_l2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatience\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdendrogram_cutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdendrogram_cutoff\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m                      \u001B[49m\u001B[43maccur_thres\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccur_thres\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmtl_tasks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmtl_tasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m res\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:498\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set, scale, quant_normed, nrun, regression, ncell, nsubset, per_sample, subset_selection, maxpool_percentages, nfilter_choice, learning_rate, coeff_l1, coeff_l2, dropout, dropout_p, max_epochs, patience, dendrogram_cutoff, accur_thres, verbose, mtl_tasks)\u001B[0m\n\u001B[1;32m    495\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCells pooled: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    497\u001B[0m \u001B[38;5;66;03m# build the neural network\u001B[39;00m\n\u001B[0;32m--> 498\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mncell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnmark\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnfilter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mcoeff_l1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoeff_l2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout_p\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mregression\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_classes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmtl_tasks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmtl_tasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;28mprint\u001B[39m(model\u001B[38;5;241m.\u001B[39msummary())\n\u001B[1;32m    502\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mlosses:\u001B[39m\u001B[38;5;124m'\u001B[39m, model\u001B[38;5;241m.\u001B[39mlosses)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:743\u001B[0m, in \u001B[0;36mbuild_model\u001B[0;34m(ncell, nmark, nfilter, coeff_l1, coeff_l2, k, dropout, dropout_p, regression, n_classes, lr, mtl_tasks)\u001B[0m\n\u001B[1;32m    733\u001B[0m model \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mModel(inputs\u001B[38;5;241m=\u001B[39mdata_input, outputs\u001B[38;5;241m=\u001B[39moutput_layers)\n\u001B[1;32m    734\u001B[0m \u001B[38;5;66;03m# weights = []\u001B[39;00m\n\u001B[1;32m    735\u001B[0m \u001B[38;5;66;03m# for i, loss in enumerate(losses):\u001B[39;00m\n\u001B[1;32m    736\u001B[0m \u001B[38;5;66;03m#     sigma = tf.keras.backend.variable(value=0.5, dtype=tf.float32,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    740\u001B[0m \u001B[38;5;66;03m#     print(sigma)\u001B[39;00m\n\u001B[1;32m    741\u001B[0m \u001B[38;5;66;03m#     model.add_weight(sigma.ref())\u001B[39;00m\n\u001B[0;32m--> 743\u001B[0m loss, weights \u001B[38;5;241m=\u001B[39m \u001B[43muncertainty_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlosses\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    744\u001B[0m model\u001B[38;5;241m.\u001B[39madd_loss(loss)\n\u001B[1;32m    746\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39mlr),\n\u001B[1;32m    747\u001B[0m               loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    748\u001B[0m               metrics\u001B[38;5;241m=\u001B[39mmetrics)\n",
      "\u001B[0;31mTypeError\u001B[0m: uncertainty_loss() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": [
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "importlib.reload(cellCnn.model)\n",
    "importlib.reload(cellCnn)\n",
    "importlib.reload(cellCnn.utils)\n",
    "from cellCnn.utils import *\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "from cellCnn import *\n",
    "\n",
    "\n",
    "kf_split = 2\n",
    "for batch_size, values, in batch_size_dict.items():\n",
    "    # for regression task stratified is wrong since there are no classes\n",
    "    freq_idx =3\n",
    "    X, cd8, y = values[0], values[1], values[2]\n",
    "    cd8 = [series[freq_idx] for series in cd8]\n",
    "\n",
    "    X_test, X_train, X_valid, cd8_test, cd8_train, cd8_valid, y_test, y_train, y_valid = split_test_train_valid(\n",
    "        X, cd8, y,\n",
    "        train_perc=train_perc,\n",
    "        test_perc=test_perc,\n",
    "        valid_perc=0.5)\n",
    "    outdir_pheno_reg_cd8 = f'{outdir_cd8}/models/ms_class_cd8_{batch_size}_psFalse'\n",
    "\n",
    "    # todo nsubset parameter maybe different\n",
    "    # yet you need to put phenotype data in frist place\n",
    "    model = get_fitted_model(X_train, X_valid, y_train, y_valid,\n",
    "                             nsubset=100,\n",
    "                             nfilters=[3, 15, 25, 35], coeff_l1=0,\n",
    "                             max_epochs=100, nrun=10, learning_rate=None,\n",
    "                             ncell=200,\n",
    "                             per_sample=False, regression=False,\n",
    "                             outdir=outdir_pheno_reg_cd8, verbose=False, mtl_tasks=1)\n",
    "    model_container_cd8_2.append(model)\n",
    "print('DONE building models')\n",
    "print('DONE class with per_sampel false')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model_container_cd8_outlier = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% outlier\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "importlib.reload(cellCnn.model)\n",
    "importlib.reload(cellCnn)\n",
    "importlib.reload(cellCnn.utils)\n",
    "from cellCnn.utils import *\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "from cellCnn import *\n",
    "\n",
    "\n",
    "kf_split = 2\n",
    "for batch_size, values, in batch_size_dict.items():\n",
    "    # for regression task stratified is wrong since there are no classes\n",
    "    freq_idx =3\n",
    "    X, cd8, y = values[0], values[1], values[2]\n",
    "    cd8 = [series[freq_idx] for series in cd8]\n",
    "\n",
    "    X_test, X_train, X_valid, cd8_test, cd8_train, cd8_valid, y_test, y_train, y_valid = split_test_train_valid(\n",
    "        X, cd8, y,\n",
    "        train_perc=train_perc,\n",
    "        test_perc=test_perc,\n",
    "        valid_perc=0.5)\n",
    "    outdir_pheno_reg_cd8 = f'{outdir_cd8}/models/ms_class_cd8_{batch_size}_psFalse'\n",
    "\n",
    "    # todo nsubset parameter maybe different\n",
    "    # yet you need to put phenotype data in frist place\n",
    "    model = get_fitted_model(X_train, X_valid, y_train, y_valid,\n",
    "                             nsubset=100,\n",
    "                             nfilters=[3, 15, 25, 35], coeff_l1=0,\n",
    "                             max_epochs=100, nrun=10, learning_rate=None,\n",
    "                             ncell=200, subset_selection='outlier',\n",
    "                             per_sample=False, regression=False,\n",
    "                             outdir=outdir_pheno_reg_cd8, verbose=False, mtl_tasks=1)\n",
    "    model_container_cd8_outlier.append(model)\n",
    "print('DONE building models')\n",
    "print('DONE class with per_sampel false')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
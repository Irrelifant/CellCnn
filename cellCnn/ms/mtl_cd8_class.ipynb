{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 10:10:24.337624: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-24 10:10:24.337672: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-24 10:10:24.338283: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "import cellCnn\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "### (from: https://github.com/eiriniar/CellCnn/blob/0413a9f49fe0831c8fe3280957fb341f9e028d2d/cellCnn/examples/NK_cell_ungated.ipynb ) AND https://github.com/eiriniar/CellCnn/blob/0413a9f49fe0831c8fe3280957fb341f9e028d2d/cellCnn/examples/PBMC.ipynb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cellCnn.ms.utils.helpers import get_min_mean_from_clusters, get_chunks\n",
    "from cellCnn.utils import mkdir_p\n",
    "from cellCnn.plotting import plot_results\n",
    "from cellCnn.ms.utils.helpers import get_chunks\n",
    "from cellCnn.ms.utils.helpers import print_regression_model_stats\n",
    "from cellCnn.plotting import plot_results\n",
    "from cellCnn.utils import mkdir_p\n",
    "from cellCnn.utils import save_results\n",
    "from cellCnn.ms.utils.helpers import get_fitted_model\n",
    "from cellCnn.ms.utils.helpers import split_test_valid_train\n",
    "from cellCnn.ms.utils.helpers import calc_frequencies, get_chunks_from_df\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "##### state vars\n",
    "cytokines = ['CCR2', 'CCR4', 'CCR6', 'CCR7', 'CXCR4', 'CXCR5', 'CD103', 'CD14', 'CD20', 'CD25', 'CD27', 'CD28', 'CD3',\n",
    "             'CD4', 'CD45RA', 'CD45RO', 'CD56', 'CD57', 'CD69', 'CD8', 'TCRgd', 'PD.1', 'GM.CSF', 'IFN.g', 'IL.10',\n",
    "             'IL.13', 'IL.17A', 'IL.2', 'IL.21', 'IL.22', 'IL.3', 'IL.4', 'IL.6', 'IL.9', 'TNF.a']\n",
    "infile = 'cohort_denoised_clustered_diagnosis_patients.csv'\n",
    "indir = 'data/input.nosync'\n",
    "outdir = 'out_ms_default'\n",
    "rand_seed = 123\n",
    "train_perc = 0.7\n",
    "test_perc = 0.3\n",
    "batch_size_pheno = 840 # deprecated  # so a size of 8425 is about equally sized in batches\n",
    "batch_size_cd4 = 550  # deprecated #so a size of 550 gets me 16 batches for cd4\n",
    "## information from ms_data project\n",
    "cluster_to_celltype_dict = {0: 'b', 1: 'cd4', 3: 'nkt', 8: 'cd8', 10: 'nk', 11: 'my', 16: 'dg'}\n",
    "outfolder = 'mtl_1'\n",
    "mkdir_p(outfolder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(16889, 38)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(rand_seed)\n",
    "mkdir_p(outdir)\n",
    "df = pd.read_csv(os.path.join(indir, infile), index_col=0)\n",
    "df = df.drop_duplicates()  ### reduces overfitting at cost of fewer data\n",
    "df.shape\n",
    "##### no duplicates in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# pitch: key = gate_source, value = dict{diagnosis: df OR freq?}\n",
    "rrms_df = df[df['diagnosis'] == 'RRMS']\n",
    "rrms_patients2df = {id: patient_df.drop(columns=['diagnosis', 'gate_source']) for id, patient_df in\n",
    "                    rrms_df.groupby('gate_source')}\n",
    "nindc_df = df[df['diagnosis'] == 'NINDC']\n",
    "nindc_patients2df = {id: patient_df.drop(columns=['diagnosis', 'gate_source']) for id, patient_df in\n",
    "                     nindc_df.groupby('gate_source')}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### split by diagnosis state\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies: \n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#### here we could see freq differences across the 2 groups\n",
    "print('Frequencies: ')\n",
    "rrms_patients_freq = {id: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list=True) for id, patient_df in\n",
    "                      rrms_patients2df.items()}\n",
    "nindc_patients_freq = {id: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list=True) for id, patient_df\n",
    "                       in nindc_patients2df.items()}\n",
    "print('DONE')\n",
    "# we got 31 patients each"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### celltype frequencies\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/5d38cf1d6tvdyny38zb_66540000gn/T/ipykernel_54229/1790410289.py:3: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "data": {
      "text/plain": "cluster      0    1   3    8   10  11  16\ngate_source                              \n3.0          60  119   6   30   5   5   0\n4.0          15   46   0   45   2   1  13\n5.0          33  131   0   70   2   2   4\n8.0          24  122   0   31  10  11   4\n9.0          72  270   2  137  11  10   4\n...          ..  ...  ..  ...  ..  ..  ..\n128.0         4    6   4    6   1   6   0\n130.0        24   82   2   56   8   4   0\n131.0        20   48   2   14  13   7   0\n132.0         8   35   7   16   1   1  10\n133.0        26   48   3   37   8  12   6\n\n[62 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>cluster</th>\n      <th>0</th>\n      <th>1</th>\n      <th>3</th>\n      <th>8</th>\n      <th>10</th>\n      <th>11</th>\n      <th>16</th>\n    </tr>\n    <tr>\n      <th>gate_source</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3.0</th>\n      <td>60</td>\n      <td>119</td>\n      <td>6</td>\n      <td>30</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>15</td>\n      <td>46</td>\n      <td>0</td>\n      <td>45</td>\n      <td>2</td>\n      <td>1</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>33</td>\n      <td>131</td>\n      <td>0</td>\n      <td>70</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8.0</th>\n      <td>24</td>\n      <td>122</td>\n      <td>0</td>\n      <td>31</td>\n      <td>10</td>\n      <td>11</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>9.0</th>\n      <td>72</td>\n      <td>270</td>\n      <td>2</td>\n      <td>137</td>\n      <td>11</td>\n      <td>10</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>128.0</th>\n      <td>4</td>\n      <td>6</td>\n      <td>4</td>\n      <td>6</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>130.0</th>\n      <td>24</td>\n      <td>82</td>\n      <td>2</td>\n      <td>56</td>\n      <td>8</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>131.0</th>\n      <td>20</td>\n      <td>48</td>\n      <td>2</td>\n      <td>14</td>\n      <td>13</td>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>132.0</th>\n      <td>8</td>\n      <td>35</td>\n      <td>7</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>133.0</th>\n      <td>26</td>\n      <td>48</td>\n      <td>3</td>\n      <td>37</td>\n      <td>8</td>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>62 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clusters_conf_table = pd.crosstab(df['gate_source'], df['cluster'])\n",
    "sns.heatmap(patients_clusters_conf_table, annot=False, vmax=100)\n",
    "plt.show()\n",
    "#plt.savefig('images/patient_vs_cluster_conf_table.png')\n",
    "patients_clusters_conf_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: batches created\n"
     ]
    }
   ],
   "source": [
    "# todo ich muss eigentlich die frequency pro batch berechnen...\n",
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "\n",
    "# batch_sizes = [40,80,120, 160]\n",
    "batch_size_dict = dict()\n",
    "batch_sizes = [120]\n",
    "for batch_size in batch_sizes:\n",
    "    ### desease states 1 = RRMS and 0 = NINDC\n",
    "    selection_pool_rrms_cd8 = get_chunks_from_df(rrms_patients2df,\n",
    "                           freq_df=rrms_patients_freq,\n",
    "                           desease_state=1,\n",
    "                           batch_size=batch_size)\n",
    "    selection_pool_nindc_cd8 = get_chunks_from_df(nindc_patients2df,\n",
    "                           freq_df=nindc_patients_freq,\n",
    "                           desease_state=0,\n",
    "                           batch_size=batch_size)\n",
    "\n",
    "    # make sure list are equally long:\n",
    "    if len(selection_pool_rrms_cd8) > len(selection_pool_nindc_cd8):\n",
    "        selection_pool_rrms_cd8 = selection_pool_rrms_cd8[:len(selection_pool_nindc_cd8)]\n",
    "    elif len(selection_pool_rrms_cd8) < len(selection_pool_nindc_cd8):\n",
    "        selection_pool_nindc_cd8 = selection_pool_nindc_cd8[:len(selection_pool_rrms_cd8)]\n",
    "\n",
    "    all_chunks = selection_pool_rrms_cd8 + selection_pool_nindc_cd8\n",
    "    np.random.shuffle(all_chunks)\n",
    "\n",
    "    X = [selection[0] for selection in all_chunks]\n",
    "    freqs = [selection[1] for selection in all_chunks]\n",
    "    Y = [selection[2] for selection in all_chunks]\n",
    "    batch_size_dict[batch_size] = (X, freqs, Y)\n",
    "\n",
    "print('DONE: batches created')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### Also ich brauch nicht mehr nach cell types in den batches suchen, es ist recht egal.\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "### CD8 Freq regression task + MTL\n",
    "model_container_cd8 = []\n",
    "stats_dict_reg_cd8 = dict()\n",
    "outdir_cd8 = 'mtl/class/cd8'\n",
    "mkdir_p(outdir_cd8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLING...\n",
      "in mtl: split inputs\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Model: \"model_87\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data_input (InputLayer)        [(None, 200, 35)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1 (Conv1D)                 (None, 200, 35)      1260        ['data_input[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_87 (Lambda)             (None, 35)           0           ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_87 (Dropout)           (None, 35)           0           ['lambda_87[0][0]']              \n",
      "                                                                                                  \n",
      " input_desease (InputLayer)     [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_task_1 (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " output_desease (Dense)         (None, 2)            72          ['dropout_87[0][0]']             \n",
      "                                                                                                  \n",
      " output_freq_1 (Dense)          (None, 1)            36          ['dropout_87[0][0]']             \n",
      "                                                                                                  \n",
      " revised_uncertainty_loss_v2_87  [(None, 2),         2           ['input_desease[0][0]',          \n",
      "  (RevisedUncertaintyLossV2)     (None, 1)]                       'input_task_1[0][0]',           \n",
      "                                                                  'output_desease[0][0]',         \n",
      "                                                                  'output_freq_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,370\n",
      "Trainable params: 1,370\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 20:53:25.315216: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-24 20:53:25.315240: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-24 20:53:25.316489: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 20:53:26.363382: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-24 20:53:26.363402: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-24 20:53:26.485086: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-03-24 20:53:26.486262: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-03-24 20:53:26.488623: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: test/stats/tensorboard/model_87_1648151605.3147619/train/plugins/profile/2022_03_24_20_53_26\n",
      "\n",
      "2022-03-24 20:53:26.490423: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to test/stats/tensorboard/model_87_1648151605.3147619/train/plugins/profile/2022_03_24_20_53_26/Eliass-MacBook-Pro.local.trace.json.gz\n",
      "2022-03-24 20:53:26.492618: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: test/stats/tensorboard/model_87_1648151605.3147619/train/plugins/profile/2022_03_24_20_53_26\n",
      "\n",
      "2022-03-24 20:53:26.492850: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to test/stats/tensorboard/model_87_1648151605.3147619/train/plugins/profile/2022_03_24_20_53_26/Eliass-MacBook-Pro.local.memory_profile.json.gz\n",
      "2022-03-24 20:53:26.494496: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: test/stats/tensorboard/model_87_1648151605.3147619/train/plugins/profile/2022_03_24_20_53_26\n",
      "Dumped tool data for xplane.pb to test/stats/tensorboard/model_87_1648151605.3147619/train/plugins/profile/2022_03_24_20_53_26/Eliass-MacBook-Pro.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to test/stats/tensorboard/model_87_1648151605.3147619/train/plugins/profile/2022_03_24_20_53_26/Eliass-MacBook-Pro.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to test/stats/tensorboard/model_87_1648151605.3147619/train/plugins/profile/2022_03_24_20_53_26/Eliass-MacBook-Pro.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to test/stats/tensorboard/model_87_1648151605.3147619/train/plugins/profile/2022_03_24_20_53_26/Eliass-MacBook-Pro.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to test/stats/tensorboard/model_87_1648151605.3147619/train/plugins/profile/2022_03_24_20_53_26/Eliass-MacBook-Pro.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLING...\n",
      "in mtl: split inputs\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 1.8595 - revised_uncertainty_loss_v2_87_accuracy: 0.5600 - revised_uncertainty_loss_v2_87_1_mean_squared_error: 0.1803\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Model: \"model_88\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data_input (InputLayer)        [(None, 200, 35)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1 (Conv1D)                 (None, 200, 25)      900         ['data_input[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_88 (Lambda)             (None, 25)           0           ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_88 (Dropout)           (None, 25)           0           ['lambda_88[0][0]']              \n",
      "                                                                                                  \n",
      " input_desease (InputLayer)     [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_task_1 (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " output_desease (Dense)         (None, 2)            52          ['dropout_88[0][0]']             \n",
      "                                                                                                  \n",
      " output_freq_1 (Dense)          (None, 1)            26          ['dropout_88[0][0]']             \n",
      "                                                                                                  \n",
      " revised_uncertainty_loss_v2_88  [(None, 2),         2           ['input_desease[0][0]',          \n",
      "  (RevisedUncertaintyLossV2)     (None, 1)]                       'input_task_1[0][0]',           \n",
      "                                                                  'output_desease[0][0]',         \n",
      "                                                                  'output_freq_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 980\n",
      "Trainable params: 980\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 20:53:39.473361: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-24 20:53:39.473424: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-24 20:53:39.474277: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 20:53:40.724818: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-24 20:53:40.724846: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-24 20:53:40.850684: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-03-24 20:53:40.852857: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-03-24 20:53:40.854643: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: test/stats/tensorboard/model_88_1648151619.472648/train/plugins/profile/2022_03_24_20_53_40\n",
      "\n",
      "2022-03-24 20:53:40.856996: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to test/stats/tensorboard/model_88_1648151619.472648/train/plugins/profile/2022_03_24_20_53_40/Eliass-MacBook-Pro.local.trace.json.gz\n",
      "2022-03-24 20:53:40.859696: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: test/stats/tensorboard/model_88_1648151619.472648/train/plugins/profile/2022_03_24_20_53_40\n",
      "\n",
      "2022-03-24 20:53:40.860032: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to test/stats/tensorboard/model_88_1648151619.472648/train/plugins/profile/2022_03_24_20_53_40/Eliass-MacBook-Pro.local.memory_profile.json.gz\n",
      "2022-03-24 20:53:40.862602: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: test/stats/tensorboard/model_88_1648151619.472648/train/plugins/profile/2022_03_24_20_53_40\n",
      "Dumped tool data for xplane.pb to test/stats/tensorboard/model_88_1648151619.472648/train/plugins/profile/2022_03_24_20_53_40/Eliass-MacBook-Pro.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to test/stats/tensorboard/model_88_1648151619.472648/train/plugins/profile/2022_03_24_20_53_40/Eliass-MacBook-Pro.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to test/stats/tensorboard/model_88_1648151619.472648/train/plugins/profile/2022_03_24_20_53_40/Eliass-MacBook-Pro.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to test/stats/tensorboard/model_88_1648151619.472648/train/plugins/profile/2022_03_24_20_53_40/Eliass-MacBook-Pro.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to test/stats/tensorboard/model_88_1648151619.472648/train/plugins/profile/2022_03_24_20_53_40/Eliass-MacBook-Pro.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLING...\n",
      "in mtl: split inputs\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.5022 - revised_uncertainty_loss_v2_88_accuracy: 0.6533 - revised_uncertainty_loss_v2_88_1_mean_squared_error: 0.1750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Model: \"model_89\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data_input (InputLayer)        [(None, 200, 35)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1 (Conv1D)                 (None, 200, 15)      540         ['data_input[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_89 (Lambda)             (None, 15)           0           ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_89 (Dropout)           (None, 15)           0           ['lambda_89[0][0]']              \n",
      "                                                                                                  \n",
      " input_desease (InputLayer)     [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_task_1 (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " output_desease (Dense)         (None, 2)            32          ['dropout_89[0][0]']             \n",
      "                                                                                                  \n",
      " output_freq_1 (Dense)          (None, 1)            16          ['dropout_89[0][0]']             \n",
      "                                                                                                  \n",
      " revised_uncertainty_loss_v2_89  [(None, 2),         2           ['input_desease[0][0]',          \n",
      "  (RevisedUncertaintyLossV2)     (None, 1)]                       'input_task_1[0][0]',           \n",
      "                                                                  'output_desease[0][0]',         \n",
      "                                                                  'output_freq_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 590\n",
      "Trainable params: 590\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 20:54:36.778627: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-24 20:54:36.778697: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-24 20:54:36.779248: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 20:54:39.093105: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-24 20:54:39.093126: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-24 20:54:39.172305: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-03-24 20:54:39.173442: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-03-24 20:54:39.175388: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: test/stats/tensorboard/model_89_1648151676.777947/train/plugins/profile/2022_03_24_20_54_39\n",
      "\n",
      "2022-03-24 20:54:39.177057: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to test/stats/tensorboard/model_89_1648151676.777947/train/plugins/profile/2022_03_24_20_54_39/Eliass-MacBook-Pro.local.trace.json.gz\n",
      "2022-03-24 20:54:39.179312: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: test/stats/tensorboard/model_89_1648151676.777947/train/plugins/profile/2022_03_24_20_54_39\n",
      "\n",
      "2022-03-24 20:54:39.179724: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to test/stats/tensorboard/model_89_1648151676.777947/train/plugins/profile/2022_03_24_20_54_39/Eliass-MacBook-Pro.local.memory_profile.json.gz\n",
      "2022-03-24 20:54:39.181750: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: test/stats/tensorboard/model_89_1648151676.777947/train/plugins/profile/2022_03_24_20_54_39\n",
      "Dumped tool data for xplane.pb to test/stats/tensorboard/model_89_1648151676.777947/train/plugins/profile/2022_03_24_20_54_39/Eliass-MacBook-Pro.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to test/stats/tensorboard/model_89_1648151676.777947/train/plugins/profile/2022_03_24_20_54_39/Eliass-MacBook-Pro.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to test/stats/tensorboard/model_89_1648151676.777947/train/plugins/profile/2022_03_24_20_54_39/Eliass-MacBook-Pro.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to test/stats/tensorboard/model_89_1648151676.777947/train/plugins/profile/2022_03_24_20_54_39/Eliass-MacBook-Pro.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to test/stats/tensorboard/model_89_1648151676.777947/train/plugins/profile/2022_03_24_20_54_39/Eliass-MacBook-Pro.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLING...\n",
      "in mtl: split inputs\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.1758 - revised_uncertainty_loss_v2_89_accuracy: 0.5711 - revised_uncertainty_loss_v2_89_1_mean_squared_error: 0.1775\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "DONE building models\n",
      "DONE class with per_sampel true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport cellCnn\n",
    "from cellCnn import loss\n",
    "from cellCnn.loss import *\n",
    "import cellCnn\n",
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "importlib.reload(cellCnn.model)\n",
    "importlib.reload(cellCnn.loss)\n",
    "importlib.reload(cellCnn.utils)\n",
    "importlib.reload(cellCnn)\n",
    "from cellCnn.loss import *\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "import cellCnn\n",
    "from cellCnn.loss import RevisedUncertaintyLoss\n",
    "\n",
    "kf_split = 2\n",
    "for batch_size, values, in batch_size_dict.items():\n",
    "    # for regression task stratified is wrong since there are no classes\n",
    "    freq_idx =3\n",
    "    X, cd8, y = values[0], values[1], values[2]\n",
    "    cd8 = [series[freq_idx] for series in cd8]\n",
    "\n",
    "    X_test, X_train, X_valid, cd8_test, cd8_train, cd8_valid, y_test, y_train, y_valid = split_test_train_valid(\n",
    "        X, cd8, y,\n",
    "        train_perc=train_perc,\n",
    "        test_perc=test_perc,\n",
    "        valid_perc=0.5)\n",
    "    outdir_pheno_reg_cd8 = f'{outdir_cd8}/models/ms_class_cd8_{batch_size}'\n",
    "\n",
    "    # todo nsubset parameter maybe different\n",
    "    model = get_fitted_model(X_train, X_valid, [y_train, cd8_train], [cd8_valid, y_valid],\n",
    "                             nsubset=100,\n",
    "                             nfilters=[3, 15, 25, 35], coeff_l1=0,\n",
    "                             max_epochs=100, nrun=3, learning_rate=None,\n",
    "                             ncell=200,\n",
    "                             per_sample=True, regression=False,\n",
    "                             outdir='test', verbose=False, mtl_tasks=2)\n",
    "    model_container_cd8.append(model)\n",
    "print('DONE building models')\n",
    "print('DONE class with per_sampel true')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of loss failed: Traceback (most recent call last):\n",
      "  File \"/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 480, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 377, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 345, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 299, in update_instances\n",
      "    refs = gc.get_referrers(old)\n",
      "KeyboardInterrupt\n",
      "]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [30]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bs_idx \u001B[38;5;241m%\u001B[39m kf_split \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m: \u001B[38;5;66;03m## when the kf split amount is reaches the next batchsize is applied\u001B[39;00m\n\u001B[1;32m     11\u001B[0m     bs_idx \u001B[38;5;241m=\u001B[39m bs_idx \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 12\u001B[0m test_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[1;32m     13\u001B[0m train_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_train)\n\u001B[1;32m     14\u001B[0m valid_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_valid)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:222\u001B[0m, in \u001B[0;36mpredict\u001B[0;34m(self, new_samples, ncell_per_sample)\u001B[0m\n\u001B[1;32m    218\u001B[0m ncell_pooled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mint\u001B[39m(maxpool_percentage \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m100.\u001B[39m \u001B[38;5;241m*\u001B[39m ncell_per_sample))\n\u001B[1;32m    220\u001B[0m \u001B[38;5;66;03m# build the model architecture\u001B[39;00m\n\u001B[1;32m    221\u001B[0m model \u001B[38;5;241m=\u001B[39m build_model(ncell_per_sample, nmark,\n\u001B[0;32m--> 222\u001B[0m                     nfilter\u001B[38;5;241m=\u001B[39mnfilter, coeff_l1\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, coeff_l2\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m    223\u001B[0m                     k\u001B[38;5;241m=\u001B[39mncell_pooled, dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dropout_p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m    224\u001B[0m                     regression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregression, n_classes\u001B[38;5;241m=\u001B[39mn_classes, lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, mtl_tasks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmtl_tasks)\n\u001B[1;32m    226\u001B[0m \u001B[38;5;66;03m# and load the learned filter and output weights\u001B[39;00m\n\u001B[1;32m    227\u001B[0m weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbest_3_nets\u001B[39m\u001B[38;5;124m'\u001B[39m][i_enum]\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:731\u001B[0m, in \u001B[0;36mbuild_model\u001B[0;34m(ncell, nmark, nfilter, coeff_l1, coeff_l2, k, dropout, dropout_p, regression, n_classes, lr, mtl_tasks)\u001B[0m\n\u001B[1;32m    727\u001B[0m     y_task_inputs[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtask_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m layers\u001B[38;5;241m.\u001B[39mInput(shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m,), name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_task_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    729\u001B[0m \u001B[38;5;66;03m# dynamically defining the inputs, the user needs to insert as many as tasks (obviously...)\u001B[39;00m\n\u001B[1;32m    730\u001B[0m \u001B[38;5;66;03m# todo is there any solution that solves this better (by taking the y_train´´ as those )\u001B[39;00m\n\u001B[0;32m--> 731\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mRevisedUncertaintyLoss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlosses\u001B[49m\u001B[43m)\u001B[49m([y_pheno, \u001B[38;5;241m*\u001B[39my_task_inputs\u001B[38;5;241m.\u001B[39mvalues(), \u001B[38;5;241m*\u001B[39moutput_layers])\n\u001B[1;32m    732\u001B[0m \u001B[38;5;66;03m# evtl pooled statt output layers ?\u001B[39;00m\n\u001B[1;32m    733\u001B[0m model \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mModel(inputs\u001B[38;5;241m=\u001B[39m[data_input, y_pheno, \u001B[38;5;241m*\u001B[39my_task_inputs\u001B[38;5;241m.\u001B[39mvalues()], outputs\u001B[38;5;241m=\u001B[39mout)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/loss.py:8\u001B[0m, in \u001B[0;36mRevisedUncertaintyLoss.__init__\u001B[0;34m(self, loss_list, *args, **kwargs)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, loss_list, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m----> 8\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mRevisedUncertaintyLoss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_list \u001B[38;5;241m=\u001B[39m loss_list\n",
      "\u001B[0;31mTypeError\u001B[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "accs = []\n",
    "\n",
    "# what predict does is: Iterating over the best 3 nets and return an array per net with the predictions for all samples!\n",
    "bs_idx = 1\n",
    "for i, model in enumerate(model_container_cd8):\n",
    "    stats_file = open(f\"{outdir_cd8}/stats_class_{model.ncell}_{model.nsubset}.txt\", \"w+\")\n",
    "    stats_file.write(f\"Model {i}; Batchsize: {batch_sizes[bs_idx-1]}\\n\")\n",
    "    if bs_idx % kf_split == 0: ## when the kf split amount is reaches the next batchsize is applied\n",
    "        bs_idx = bs_idx +1\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "    #print_regression_model_stats(test_pred, b_test)\n",
    "    test_pred_abs = [1 if pred[0]>pred[1] else 0 for pred in test_pred[0]]\n",
    "    train_pred_abs = [1 if pred[0]>pred[1] else 0 for pred in train_pred[0]]\n",
    "    valid_pred_abs = [1 if pred[0]>pred[1] else 0 for pred in valid_pred[0]]\n",
    "    acc_test = accuracy_score(y_test,  test_pred_abs)\n",
    "    acc_train = accuracy_score(y_train,  train_pred_abs)\n",
    "    acc_valid = accuracy_score(y_valid,  valid_pred_abs)\n",
    "    accs.append(acc_test)\n",
    "\n",
    "    stats_file.write('Desease: \\n')\n",
    "    stats_file.write(f'Acc y test {acc_test}\\n')\n",
    "    stats_file.write(f'Acc y train {acc_train}\\n')\n",
    "    stats_file.write(f'Acc y valid {acc_valid}\\n')\n",
    "\n",
    "    mse_test_cd8 = mean_squared_error(cd8_test, test_pred[1])\n",
    "    mse_train_cd8 = mean_squared_error(cd8_train, train_pred[1])\n",
    "    mse_valid_cd8 = mean_squared_error(cd8_valid, valid_pred[1])\n",
    "    mses.append(mse_test_cd8)\n",
    "\n",
    "    stats_file.write('Cd8: \\n')\n",
    "    stats_file.write(f'MSE y test {mse_test_cd8}\\n')\n",
    "    stats_file.write(f'MSE y train {mse_train_cd8}\\n')\n",
    "    stats_file.write(f'MSE y valid {mse_valid_cd8}\\n')\n",
    "    stats_file.write('\\n')\n",
    "    stats_file.close()\n",
    "print('DONE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "### CD8 Freq regression task + MTL\n",
    "model_container_cd8_class = []\n",
    "stats_dict_cd8_class = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build called\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret initializer identifier: <tf.Variable 'revised_uncertainty_loss_56/sigmas_sq_0:0' shape=() dtype=float32, numpy=0.0>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [31]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     22\u001B[0m     outdir_pheno_reg_cd8 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutdir_cd8\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/models/ms_class_cd8_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatch_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_psFalse\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;66;03m# todo nsubset parameter maybe different\u001B[39;00m\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;66;03m# yet you need to put phenotype data in frist place\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m     model \u001B[38;5;241m=\u001B[39m get_fitted_model(X_train, X_valid, [y_train, cd8_train], [y_valid, cd8_valid],\n\u001B[1;32m     27\u001B[0m                              nsubset\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[1;32m     28\u001B[0m                              nfilters\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m35\u001B[39m], coeff_l1\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     29\u001B[0m                              max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, nrun\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     30\u001B[0m                              ncell\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m,\n\u001B[1;32m     31\u001B[0m                              per_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, regression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     32\u001B[0m                              outdir\u001B[38;5;241m=\u001B[39moutdir_pheno_reg_cd8, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, mtl_tasks\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     33\u001B[0m     model_container_cd8_class\u001B[38;5;241m.\u001B[39mappend(model)\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDONE building models\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/ms/utils/helpers.py:169\u001B[0m, in \u001B[0;36mget_fitted_model\u001B[0;34m(X_train, X_valid, y_train, y_valid, nrun, ncell, nsubset, nfilters, coeff_l2, coeff_l1, max_epochs, learning_rate, outdir, subset_selection, per_sample, regression, verbose, result, mtl_tasks)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;66;03m## parameters from PBMC example\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;66;03m###per_sample bei regression\u001B[39;00m\n\u001B[1;32m    163\u001B[0m model \u001B[38;5;241m=\u001B[39m CellCnn(nrun\u001B[38;5;241m=\u001B[39mnrun, ncell\u001B[38;5;241m=\u001B[39mncell, nsubset\u001B[38;5;241m=\u001B[39mnsubset,\n\u001B[1;32m    164\u001B[0m                 nfilter_choice\u001B[38;5;241m=\u001B[39mnfilters, learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate,\n\u001B[1;32m    165\u001B[0m                 coeff_l2\u001B[38;5;241m=\u001B[39mcoeff_l2, coeff_l1\u001B[38;5;241m=\u001B[39mcoeff_l1, subset_selection\u001B[38;5;241m=\u001B[39msubset_selection,\n\u001B[1;32m    166\u001B[0m                 max_epochs\u001B[38;5;241m=\u001B[39mmax_epochs, per_sample\u001B[38;5;241m=\u001B[39mper_sample,\n\u001B[1;32m    167\u001B[0m                 regression\u001B[38;5;241m=\u001B[39mregression, verbose\u001B[38;5;241m=\u001B[39mverbose, mtl_tasks\u001B[38;5;241m=\u001B[39mmtl_tasks)\n\u001B[0;32m--> 169\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_phenotypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mvalid_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_phenotypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_valid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m                  \u001B[49m\u001B[43moutdir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutdir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:163\u001B[0m, in \u001B[0;36mCellCnn.fit\u001B[0;34m(self, train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, train_samples, train_phenotypes, outdir, valid_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    127\u001B[0m         valid_phenotypes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, generate_valid_set\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;124;03m\"\"\" Trains a CellCnn model.\u001B[39;00m\n\u001B[1;32m    130\u001B[0m \n\u001B[1;32m    131\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;124;03m        - n_classes : number of output classes\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 163\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_phenotypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutdir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mvalid_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_phenotypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerate_valid_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mscale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnrun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnrun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mregression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mncell\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mncell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnsubset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnsubset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mper_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mper_sample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m                      \u001B[49m\u001B[43msubset_selection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubset_selection\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mmaxpool_percentages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaxpool_percentages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mnfilter_choice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnfilter_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mcoeff_l1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_l1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoeff_l2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_l2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatience\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdendrogram_cutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdendrogram_cutoff\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m                      \u001B[49m\u001B[43maccur_thres\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccur_thres\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmtl_tasks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmtl_tasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m res\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:500\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set, scale, quant_normed, nrun, regression, ncell, nsubset, per_sample, subset_selection, maxpool_percentages, nfilter_choice, learning_rate, coeff_l1, coeff_l2, dropout, dropout_p, max_epochs, patience, dendrogram_cutoff, accur_thres, verbose, mtl_tasks)\u001B[0m\n\u001B[1;32m    497\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCells pooled: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    499\u001B[0m \u001B[38;5;66;03m# build the neural network\u001B[39;00m\n\u001B[0;32m--> 500\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mncell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnmark\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnfilter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mcoeff_l1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoeff_l2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout_p\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mregression\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_classes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmtl_tasks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmtl_tasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    503\u001B[0m statspath\u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(outdir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstats\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    504\u001B[0m keras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mplot_model(model, statspath, show_shapes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:729\u001B[0m, in \u001B[0;36mbuild_model\u001B[0;34m(ncell, nmark, nfilter, coeff_l1, coeff_l2, k, dropout, dropout_p, regression, n_classes, lr, mtl_tasks)\u001B[0m\n\u001B[1;32m    725\u001B[0m     y_task_inputs[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtask_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m layers\u001B[38;5;241m.\u001B[39mInput(shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m,), name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_task_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    727\u001B[0m \u001B[38;5;66;03m# dynamically defining the inputs, the user needs to insert as many as tasks (obviously...)\u001B[39;00m\n\u001B[1;32m    728\u001B[0m \u001B[38;5;66;03m# todo is there any solution that solves this better (by taking the y_train´´ as those )\u001B[39;00m\n\u001B[0;32m--> 729\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mRevisedUncertaintyLoss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlosses\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43my_pheno\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43my_task_inputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moutput_layers\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    730\u001B[0m \u001B[38;5;66;03m# evtl pooled statt output layers ?\u001B[39;00m\n\u001B[1;32m    731\u001B[0m model \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mModel(inputs\u001B[38;5;241m=\u001B[39m[data_input, y_pheno, \u001B[38;5;241m*\u001B[39my_task_inputs\u001B[38;5;241m.\u001B[39mvalues()], outputs\u001B[38;5;241m=\u001B[39mout)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/loss.py:21\u001B[0m, in \u001B[0;36mRevisedUncertaintyLoss.build\u001B[0;34m(self, input_shape)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_list)):\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;66;03m# random_uniform ?? initial var\u001B[39;00m\n\u001B[1;32m     19\u001B[0m     var \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39mvariable(value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     20\u001B[0m                                     constraint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m t: tf\u001B[38;5;241m.\u001B[39mclip_by_value(t, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m), name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msigmas_sq_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msigmas_sq \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_weight\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlog_var\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minitializer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m]\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# self.sigmas_sq = np.array(sigma_list)\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_list) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msigmas_sq)\n",
      "\u001B[0;31mValueError\u001B[0m: Could not interpret initializer identifier: <tf.Variable 'revised_uncertainty_loss_56/sigmas_sq_0:0' shape=() dtype=float32, numpy=0.0>"
     ]
    }
   ],
   "source": [
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "importlib.reload(cellCnn.model)\n",
    "importlib.reload(cellCnn)\n",
    "importlib.reload(cellCnn.utils)\n",
    "from cellCnn.utils import *\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "from cellCnn import *\n",
    "\n",
    "\n",
    "kf_split = 2\n",
    "for batch_size, values, in batch_size_dict.items():\n",
    "    # for regression task stratified is wrong since there are no classes\n",
    "    freq_idx =3\n",
    "    X, cd8, y = values[0], values[1], values[2]\n",
    "    cd8 = [series[freq_idx] for series in cd8]\n",
    "\n",
    "    X_test, X_train, X_valid, cd8_test, cd8_train, cd8_valid, y_test, y_train, y_valid = split_test_train_valid(\n",
    "        X, cd8, y,\n",
    "        train_perc=train_perc,\n",
    "        test_perc=test_perc,\n",
    "        valid_perc=0.5)\n",
    "    outdir_pheno_reg_cd8 = f'{outdir_cd8}/models/ms_class_cd8_{batch_size}_psFalse'\n",
    "\n",
    "    # todo nsubset parameter maybe different\n",
    "    # yet you need to put phenotype data in frist place\n",
    "    model = get_fitted_model(X_train, X_valid, [y_train, cd8_train], [y_valid, cd8_valid],\n",
    "                             nsubset=100,\n",
    "                             nfilters=[3, 15, 25, 35], coeff_l1=0,\n",
    "                             max_epochs=100, nrun=10, learning_rate=None,\n",
    "                             ncell=200,\n",
    "                             per_sample=False, regression=False,\n",
    "                             outdir=outdir_pheno_reg_cd8, verbose=False, mtl_tasks=2)\n",
    "    model_container_cd8_class.append(model)\n",
    "print('DONE building models')\n",
    "print('DONE class with per_sampel false')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### Bughunter: stl to compare\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 09:31:11.497542: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-24 09:31:11.497566: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-24 09:31:11.497702: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-03-24 09:31:11.822029: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-24 09:31:11.822048: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-24 09:31:11.822180: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-03-24 09:31:11.894731: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-24 09:31:11.894749: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-24 09:31:11.894890: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-03-24 09:31:11.903003: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-24 09:31:11.903021: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-24 09:31:11.903047: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build called\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "sigma 0\n",
      "<tf.Variable 'revised_uncertainty_loss_4/sigmas_sq_0:0' shape=() dtype=float32>\n",
      "listed_loss task 0\n",
      "Tensor(\"revised_uncertainty_loss_4/loss:0\", shape=(), dtype=float32)\n",
      "loss\n",
      "Tensor(\"revised_uncertainty_loss_4/Min:0\", shape=(), dtype=float32)\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " data_input (InputLayer)        [(None, 200, 35)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1 (Conv1D)                 (None, 200, 3)       108         ['data_input[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 3)            0           ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 3)            0           ['lambda_4[0][0]']               \n",
      "                                                                                                  \n",
      " input_desease (InputLayer)     [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " output_desease (Dense)         (None, 2)            8           ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " revised_uncertainty_loss_4 (Re  [(None, 2)]         0           ['input_desease[0][0]',          \n",
      " visedUncertaintyLoss)                                            'output_desease[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 116\n",
      "Trainable params: 116\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Trainfit incoming\n",
      "[0.2043026]\n",
      "[<tf.Variable 'conv1/kernel:0' shape=(1, 35, 3) dtype=float32, numpy=\n",
      "array([[[ 0.03056656, -0.03077786,  0.01926989],\n",
      "        [-0.03098062,  0.03927681, -0.03065532],\n",
      "        [-0.04764045, -0.04172216,  0.00144775],\n",
      "        [ 0.02901926, -0.04956068, -0.03800811],\n",
      "        [-0.03109701,  0.02972323,  0.02038727],\n",
      "        [ 0.01642194,  0.00393419, -0.01323188],\n",
      "        [-0.01960625,  0.01702538,  0.04648394],\n",
      "        [-0.0046679 ,  0.04084826,  0.03632977],\n",
      "        [ 0.03712741,  0.01207288, -0.02748184],\n",
      "        [ 0.02923936, -0.01362877,  0.04184444],\n",
      "        [ 0.03642204, -0.00334262, -0.03862265],\n",
      "        [ 0.01004535,  0.00970114,  0.02076003],\n",
      "        [ 0.02836795,  0.02030864,  0.03679751],\n",
      "        [ 0.02391783,  0.01456053, -0.0461463 ],\n",
      "        [-0.02370945, -0.01883486,  0.03121603],\n",
      "        [-0.00867798, -0.02372102,  0.00787641],\n",
      "        [-0.01217657,  0.02732975, -0.03869939],\n",
      "        [ 0.03943412, -0.03078023, -0.04824221],\n",
      "        [ 0.04502091,  0.00660013, -0.04513536],\n",
      "        [-0.00209055, -0.00766374, -0.01372116],\n",
      "        [-0.03279538,  0.01303579,  0.02224857],\n",
      "        [-0.01216242,  0.00971369, -0.0390035 ],\n",
      "        [ 0.01438404, -0.03837962,  0.01606151],\n",
      "        [ 0.04550621, -0.04614489,  0.04914159],\n",
      "        [-0.03602475, -0.01947323,  0.02497125],\n",
      "        [-0.00740226,  0.02052988, -0.02518777],\n",
      "        [ 0.01929722,  0.00993439, -0.01969171],\n",
      "        [ 0.00217581, -0.0154472 , -0.02421459],\n",
      "        [-0.01116852,  0.03417258, -0.04020991],\n",
      "        [ 0.01810697, -0.03963113,  0.03487948],\n",
      "        [-0.00163269,  0.04710703,  0.02055928],\n",
      "        [-0.02343407, -0.04057816,  0.01382018],\n",
      "        [-0.01420217, -0.02642709, -0.04676132],\n",
      "        [ 0.0352705 , -0.01455154,  0.03508328],\n",
      "        [ 0.00570983,  0.04621407, -0.01148106]]], dtype=float32)>, <tf.Variable 'conv1/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>, <tf.Variable 'output_desease/kernel:0' shape=(3, 2) dtype=float32, numpy=\n",
      "array([[-0.01685507,  0.0402784 ],\n",
      "       [ 0.00156047, -0.03778939],\n",
      "       [ 0.04632076, -0.03530446]], dtype=float32)>, <tf.Variable 'output_desease/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     23\u001B[0m     outdir_pheno_reg_cd8 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutdir_cd8\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/models/ms_class_cd8_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatch_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_psFalse\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;66;03m# todo nsubset parameter maybe different\u001B[39;00m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;66;03m# yet you need to put phenotype data in frist place\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m     model \u001B[38;5;241m=\u001B[39m get_fitted_model(X_train, X_valid, y_train, y_valid,\n\u001B[1;32m     28\u001B[0m                              nsubset\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[1;32m     29\u001B[0m                              nfilters\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m35\u001B[39m], coeff_l1\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     30\u001B[0m                              max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, nrun\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     31\u001B[0m                              ncell\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m,\n\u001B[1;32m     32\u001B[0m                              per_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, regression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     33\u001B[0m                              outdir\u001B[38;5;241m=\u001B[39moutdir_pheno_reg_cd8, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, mtl_tasks\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     34\u001B[0m     model_container_cd8_2\u001B[38;5;241m.\u001B[39mappend(model)\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDONE building models\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/ms/utils/helpers.py:169\u001B[0m, in \u001B[0;36mget_fitted_model\u001B[0;34m(X_train, X_valid, y_train, y_valid, nrun, ncell, nsubset, nfilters, coeff_l2, coeff_l1, max_epochs, learning_rate, outdir, subset_selection, per_sample, regression, verbose, result, mtl_tasks)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;66;03m## parameters from PBMC example\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;66;03m###per_sample bei regression\u001B[39;00m\n\u001B[1;32m    163\u001B[0m model \u001B[38;5;241m=\u001B[39m CellCnn(nrun\u001B[38;5;241m=\u001B[39mnrun, ncell\u001B[38;5;241m=\u001B[39mncell, nsubset\u001B[38;5;241m=\u001B[39mnsubset,\n\u001B[1;32m    164\u001B[0m                 nfilter_choice\u001B[38;5;241m=\u001B[39mnfilters, learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate,\n\u001B[1;32m    165\u001B[0m                 coeff_l2\u001B[38;5;241m=\u001B[39mcoeff_l2, coeff_l1\u001B[38;5;241m=\u001B[39mcoeff_l1, subset_selection\u001B[38;5;241m=\u001B[39msubset_selection,\n\u001B[1;32m    166\u001B[0m                 max_epochs\u001B[38;5;241m=\u001B[39mmax_epochs, per_sample\u001B[38;5;241m=\u001B[39mper_sample,\n\u001B[1;32m    167\u001B[0m                 regression\u001B[38;5;241m=\u001B[39mregression, verbose\u001B[38;5;241m=\u001B[39mverbose, mtl_tasks\u001B[38;5;241m=\u001B[39mmtl_tasks)\n\u001B[0;32m--> 169\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_phenotypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mvalid_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_phenotypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_valid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m                  \u001B[49m\u001B[43moutdir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutdir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:170\u001B[0m, in \u001B[0;36mCellCnn.fit\u001B[0;34m(self, train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, train_samples, train_phenotypes, outdir, valid_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    134\u001B[0m         valid_phenotypes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, generate_valid_set\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;124;03m\"\"\" Trains a CellCnn model.\u001B[39;00m\n\u001B[1;32m    137\u001B[0m \n\u001B[1;32m    138\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;124;03m        - n_classes : number of output classes\u001B[39;00m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 170\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_phenotypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutdir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mvalid_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_phenotypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerate_valid_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mscale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnrun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnrun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mregression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mncell\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mncell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnsubset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnsubset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mper_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mper_sample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m                      \u001B[49m\u001B[43msubset_selection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubset_selection\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mmaxpool_percentages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaxpool_percentages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mnfilter_choice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnfilter_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mcoeff_l1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_l1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoeff_l2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeff_l2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatience\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdendrogram_cutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdendrogram_cutoff\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m                      \u001B[49m\u001B[43maccur_thres\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccur_thres\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmtl_tasks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmtl_tasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m res\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:532\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set, scale, quant_normed, nrun, regression, ncell, nsubset, per_sample, subset_selection, maxpool_percentages, nfilter_choice, learning_rate, coeff_l1, coeff_l2, dropout, dropout_p, max_epochs, patience, dendrogram_cutoff, accur_thres, verbose, mtl_tasks)\u001B[0m\n\u001B[1;32m    530\u001B[0m \u001B[38;5;28mprint\u001B[39m(sigmas)\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28mprint\u001B[39m(model\u001B[38;5;241m.\u001B[39mtrainable_variables)\n\u001B[0;32m--> 532\u001B[0m hist \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mfit([X_tr, \u001B[38;5;241m*\u001B[39my_trains], y\u001B[38;5;241m=\u001B[39my_trains,\n\u001B[1;32m    533\u001B[0m           epochs\u001B[38;5;241m=\u001B[39mmax_epochs, batch_size\u001B[38;5;241m=\u001B[39mbs,\n\u001B[1;32m    534\u001B[0m                  callbacks\u001B[38;5;241m=\u001B[39m[check, earlyStopping, csv_logger, loss_history],\n\u001B[1;32m    535\u001B[0m           validation_data\u001B[38;5;241m=\u001B[39m([X_v, \u001B[38;5;241m*\u001B[39my_valids], y_valids), verbose\u001B[38;5;241m=\u001B[39mverbose)\n\u001B[1;32m    536\u001B[0m \u001B[38;5;66;03m#tensorboard\u001B[39;00m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrainfit done\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/model.py:532\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(train_samples, train_phenotypes, outdir, valid_samples, valid_phenotypes, generate_valid_set, scale, quant_normed, nrun, regression, ncell, nsubset, per_sample, subset_selection, maxpool_percentages, nfilter_choice, learning_rate, coeff_l1, coeff_l2, dropout, dropout_p, max_epochs, patience, dendrogram_cutoff, accur_thres, verbose, mtl_tasks)\u001B[0m\n\u001B[1;32m    530\u001B[0m \u001B[38;5;28mprint\u001B[39m(sigmas)\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28mprint\u001B[39m(model\u001B[38;5;241m.\u001B[39mtrainable_variables)\n\u001B[0;32m--> 532\u001B[0m hist \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mfit([X_tr, \u001B[38;5;241m*\u001B[39my_trains], y\u001B[38;5;241m=\u001B[39my_trains,\n\u001B[1;32m    533\u001B[0m           epochs\u001B[38;5;241m=\u001B[39mmax_epochs, batch_size\u001B[38;5;241m=\u001B[39mbs,\n\u001B[1;32m    534\u001B[0m                  callbacks\u001B[38;5;241m=\u001B[39m[check, earlyStopping, csv_logger, loss_history],\n\u001B[1;32m    535\u001B[0m           validation_data\u001B[38;5;241m=\u001B[39m([X_v, \u001B[38;5;241m*\u001B[39my_valids], y_valids), verbose\u001B[38;5;241m=\u001B[39mverbose)\n\u001B[1;32m    536\u001B[0m \u001B[38;5;66;03m#tensorboard\u001B[39;00m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrainfit done\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1147\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1144\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1147\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1162\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1159\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1161\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1162\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "importlib.reload(cellCnn.model)\n",
    "importlib.reload(cellCnn)\n",
    "importlib.reload(cellCnn.utils)\n",
    "from cellCnn.utils import *\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "from cellCnn import *\n",
    "\n",
    "\n",
    "kf_split = 2\n",
    "for batch_size, values, in batch_size_dict.items():\n",
    "    # for regression task stratified is wrong since there are no classes\n",
    "    freq_idx =3\n",
    "    X, cd8, y = values[0], values[1], values[2]\n",
    "    cd8 = [series[freq_idx] for series in cd8]\n",
    "\n",
    "    X_test, X_train, X_valid, cd8_test, cd8_train, cd8_valid, y_test, y_train, y_valid = split_test_train_valid(\n",
    "        X, cd8, y,\n",
    "        train_perc=train_perc,\n",
    "        test_perc=test_perc,\n",
    "        valid_perc=0.5)\n",
    "    outdir_pheno_reg_cd8 = f'{outdir_cd8}/models/ms_class_cd8_{batch_size}_psFalse'\n",
    "\n",
    "    # todo nsubset parameter maybe different\n",
    "    # yet you need to put phenotype data in frist place\n",
    "    model = get_fitted_model(X_train, X_valid, y_train, y_valid,\n",
    "                             nsubset=100,\n",
    "                             nfilters=[3, 15, 25, 35], coeff_l1=0,\n",
    "                             max_epochs=100, nrun=10, learning_rate=None,\n",
    "                             ncell=200,\n",
    "                             per_sample=False, regression=False,\n",
    "                             outdir=outdir_pheno_reg_cd8, verbose=False, mtl_tasks=1)\n",
    "    model_container_cd8_2.append(model)\n",
    "print('DONE building models')\n",
    "print('DONE class with per_sampel false')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model_container_cd8_outlier = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% outlier\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(cellCnn.ms.utils.helpers)\n",
    "importlib.reload(cellCnn.model)\n",
    "importlib.reload(cellCnn)\n",
    "importlib.reload(cellCnn.utils)\n",
    "from cellCnn.utils import *\n",
    "from cellCnn.ms.utils.helpers import *\n",
    "from cellCnn import *\n",
    "\n",
    "\n",
    "kf_split = 2\n",
    "for batch_size, values, in batch_size_dict.items():\n",
    "    # for regression task stratified is wrong since there are no classes\n",
    "    freq_idx =3\n",
    "    X, cd8, y = values[0], values[1], values[2]\n",
    "    cd8 = [series[freq_idx] for series in cd8]\n",
    "\n",
    "    X_test, X_train, X_valid, cd8_test, cd8_train, cd8_valid, y_test, y_train, y_valid = split_test_train_valid(\n",
    "        X, cd8, y,\n",
    "        train_perc=train_perc,\n",
    "        test_perc=test_perc,\n",
    "        valid_perc=0.5)\n",
    "    outdir_pheno_reg_cd8 = f'{outdir_cd8}/models/ms_class_cd8_{batch_size}_psFalse'\n",
    "\n",
    "    # todo nsubset parameter maybe different\n",
    "    # yet you need to put phenotype data in frist place\n",
    "    model = get_fitted_model(X_train, X_valid, y_train, y_valid,\n",
    "                             nsubset=100,\n",
    "                             nfilters=[3, 15, 25, 35], coeff_l1=0,\n",
    "                             max_epochs=100, nrun=10, learning_rate=None,\n",
    "                             ncell=200, subset_selection='outlier',\n",
    "                             per_sample=False, regression=False,\n",
    "                             outdir=outdir_pheno_reg_cd8, verbose=False, mtl_tasks=1)\n",
    "    model_container_cd8_outlier.append(model)\n",
    "print('DONE building models')\n",
    "print('DONE class with per_sampel false')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
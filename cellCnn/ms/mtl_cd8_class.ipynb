{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "% reload_ext autoreload\n",
    "% autoreload 2\n",
    "% aimport cellCnn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cellCnn\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "### (from: https://github.com/eiriniar/CellCnn/blob/0413a9f49fe0831c8fe3280957fb341f9e028d2d/cellCnn/examples/NK_cell_ungated.ipynb ) AND https://github.com/eiriniar/CellCnn/blob/0413a9f49fe0831c8fe3280957fb341f9e028d2d/cellCnn/examples/PBMC.ipynb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cellCnn.ms.utils.helpers import get_min_mean_from_clusters, get_chunks\n",
    "from cellCnn.utils import mkdir_p\n",
    "from cellCnn.plotting import plot_results\n",
    "from cellCnn.ms.utils.helpers import get_chunks\n",
    "from cellCnn.ms.utils.helpers import print_regression_model_stats\n",
    "from cellCnn.plotting import plot_results\n",
    "from cellCnn.utils import mkdir_p\n",
    "from cellCnn.utils import save_results, get_selected_cells, get_data\n",
    "from cellCnn.ms.utils.helpers import get_fitted_model\n",
    "from cellCnn.ms.utils.helpers import split_test_valid_train\n",
    "from cellCnn.ms.utils.helpers import calc_frequencies, get_chunks_from_df\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from plotting import plot_filters, discriminative_filters\n",
    "\n",
    "def reload_modules():\n",
    "    import cellCnn\n",
    "    import cellCnn.utils\n",
    "\n",
    "    importlib.reload(cellCnn.ms.utils.helpers)\n",
    "    importlib.reload(cellCnn.utils)\n",
    "    importlib.reload(cellCnn.model)\n",
    "    importlib.reload(cellCnn)\n",
    "    import cellCnn\n",
    "    import cellCnn.utils\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "##### state vars\n",
    "cytokines = ['CCR2', 'CCR4', 'CCR6', 'CCR7', 'CXCR4', 'CXCR5', 'CD103', 'CD14', 'CD20', 'CD25', 'CD27', 'CD28', 'CD3',\n",
    "             'CD4', 'CD45RA', 'CD45RO', 'CD56', 'CD57', 'CD69', 'CD8', 'TCRgd', 'PD.1', 'GM.CSF', 'IFN.g', 'IL.10',\n",
    "             'IL.13', 'IL.17A', 'IL.2', 'IL.21', 'IL.22', 'IL.3', 'IL.4', 'IL.6', 'IL.9', 'TNF.a']\n",
    "infile = 'cohort_denoised_clustered_diagnosis_patients.csv'\n",
    "indir = 'data/input.nosync'\n",
    "outdir = 'class_cd8'\n",
    "rand_seed = 123\n",
    "train_perc = 0.7\n",
    "test_perc = 0.3\n",
    "batch_size_pheno = 840  # deprecated  # so a size of 8425 is about equally sized in batches\n",
    "batch_size_cd4 = 550  # deprecated #so a size of 550 gets me 16 batches for cd4\n",
    "## information from ms_data project\n",
    "cluster_to_celltype_dict = {0: 'b', 1: 'cd4', 3: 'nkt', 8: 'cd8', 10: 'nk', 11: 'my', 16: 'dg'}\n",
    "outfolder = 'mtl_1'\n",
    "mkdir_p(outfolder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/input.nosync/cohort_denoised_clustered_diagnosis_patients.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mseed(rand_seed)\n\u001B[1;32m      2\u001B[0m mkdir_p(outdir)\n\u001B[0;32m----> 3\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(indir, infile), index_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdrop_duplicates()  \u001B[38;5;66;03m### reduces overfitting at cost of fewer data\u001B[39;00m\n\u001B[1;32m      5\u001B[0m df\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    666\u001B[0m     dialect,\n\u001B[1;32m    667\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    677\u001B[0m )\n\u001B[1;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1213\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1214\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[1;32m   1215\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[1;32m   1216\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[0;32m-> 1217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[1;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1226\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1227\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1228\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/pandas/io/common.py:789\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    784\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    785\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    786\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    788\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/input.nosync/cohort_denoised_clustered_diagnosis_patients.csv'"
     ]
    }
   ],
   "source": [
    "np.random.seed(rand_seed)\n",
    "mkdir_p(outdir)\n",
    "df = pd.read_csv(os.path.join(indir, infile), index_col=0)\n",
    "df = df.drop_duplicates()  ### reduces overfitting at cost of fewer data\n",
    "df.shape\n",
    "##### no duplicates in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pitch: key = gate_source, value = dict{diagnosis: df OR freq?}\n",
    "rrms_df = df[df['diagnosis'] == 'RRMS']\n",
    "rrms_patients2df = {id: patient_df.drop(columns=['diagnosis', 'gate_source']) for id, patient_df in\n",
    "                    rrms_df.groupby('gate_source')}\n",
    "nindc_df = df[df['diagnosis'] == 'NINDC']\n",
    "nindc_patients2df = {id: patient_df.drop(columns=['diagnosis', 'gate_source']) for id, patient_df in\n",
    "                     nindc_df.groupby('gate_source')}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### split by diagnosis state\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rrms_patients2df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#### here we could see freq differences across the 2 groups\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFrequencies: \u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m rrms_patients_freq \u001B[38;5;241m=\u001B[39m {\u001B[38;5;28mid\u001B[39m: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mid\u001B[39m, patient_df \u001B[38;5;129;01min\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m                       rrms_patients2df\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m      5\u001B[0m nindc_patients_freq \u001B[38;5;241m=\u001B[39m {\u001B[38;5;28mid\u001B[39m: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mid\u001B[39m, patient_df\n\u001B[1;32m      6\u001B[0m                        \u001B[38;5;129;01min\u001B[39;00m nindc_patients2df\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDONE\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'rrms_patients2df' is not defined"
     ]
    }
   ],
   "source": [
    "#### here we could see freq differences across the 2 groups\n",
    "print('Frequencies: ')\n",
    "rrms_patients_freq = {id: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list=True) for id, patient_df in\n",
    "                      rrms_patients2df.items()}\n",
    "nindc_patients_freq = {id: calc_frequencies(patient_df, cluster_to_celltype_dict, return_list=True) for id, patient_df\n",
    "                       in nindc_patients2df.items()}\n",
    "print('DONE')\n",
    "# we got 31 patients each"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### celltype frequencies\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rrms_patients2df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m### desease states 1 = RRMS and 0 = NINDC\u001B[39;00m\n\u001B[1;32m      2\u001B[0m batch_size_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()\n\u001B[0;32m----> 3\u001B[0m selection_pool_rrms_cd8 \u001B[38;5;241m=\u001B[39m get_chunks_from_df(rrms_patients2df,\n\u001B[1;32m      4\u001B[0m                                              freq_df\u001B[38;5;241m=\u001B[39mrrms_patients_freq,\n\u001B[1;32m      5\u001B[0m                                              desease_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      6\u001B[0m selection_pool_nindc_cd8 \u001B[38;5;241m=\u001B[39m get_chunks_from_df(nindc_patients2df,\n\u001B[1;32m      7\u001B[0m                                               freq_df\u001B[38;5;241m=\u001B[39mnindc_patients_freq,\n\u001B[1;32m      8\u001B[0m                                               desease_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# make sure list are equally long:\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'rrms_patients2df' is not defined"
     ]
    }
   ],
   "source": [
    "### desease states 1 = RRMS and 0 = NINDC\n",
    "batch_size_dict = dict()\n",
    "selection_pool_rrms_cd8 = get_chunks_from_df(rrms_patients2df,\n",
    "                                             freq_df=rrms_patients_freq,\n",
    "                                             desease_state=1)\n",
    "selection_pool_nindc_cd8 = get_chunks_from_df(nindc_patients2df,\n",
    "                                              freq_df=nindc_patients_freq,\n",
    "                                              desease_state=0)\n",
    "\n",
    "# make sure list are equally long:\n",
    "if len(selection_pool_rrms_cd8) > len(selection_pool_nindc_cd8):\n",
    "    selection_pool_rrms_cd8 = selection_pool_rrms_cd8[:len(selection_pool_nindc_cd8)]\n",
    "elif len(selection_pool_rrms_cd8) < len(selection_pool_nindc_cd8):\n",
    "    selection_pool_nindc_cd8 = selection_pool_nindc_cd8[:len(selection_pool_rrms_cd8)]\n",
    "\n",
    "all_chunks = selection_pool_rrms_cd8 + selection_pool_nindc_cd8\n",
    "np.random.shuffle(all_chunks)\n",
    "\n",
    "X = [selection[0].to_numpy() for selection in all_chunks]\n",
    "freqs = [selection[1] for selection in all_chunks]\n",
    "Y = [selection[2] for selection in all_chunks]\n",
    "\n",
    "print('DONE: batches created')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% ### Also ich brauch nicht mehr nach cell types in den batches suchen, es ist recht egal.\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_test_train_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m freq_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[1;32m      7\u001B[0m cd8 \u001B[38;5;241m=\u001B[39m [series[freq_idx] \u001B[38;5;28;01mfor\u001B[39;00m series \u001B[38;5;129;01min\u001B[39;00m freqs]\n\u001B[0;32m----> 8\u001B[0m X_test, X_train, X_valid, cd8_test, cd8_train, cd8_valid, y_test, y_train, y_valid \u001B[38;5;241m=\u001B[39m split_test_train_valid(\n\u001B[1;32m      9\u001B[0m     X, cd8, Y,\n\u001B[1;32m     10\u001B[0m     train_perc\u001B[38;5;241m=\u001B[39mtrain_perc,\n\u001B[1;32m     11\u001B[0m     test_perc\u001B[38;5;241m=\u001B[39mtest_perc,\n\u001B[1;32m     12\u001B[0m     valid_perc\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# pay attention to put in phenotype first and then freq...\u001B[39;00m\n\u001B[1;32m     15\u001B[0m model \u001B[38;5;241m=\u001B[39m get_fitted_model(X_train, X_valid, [y_train, cd8_train], [y_valid, cd8_valid, ],\n\u001B[1;32m     16\u001B[0m                          nsubset\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, ncell\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2000\u001B[39m,\n\u001B[1;32m     17\u001B[0m                          quant_normed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     21\u001B[0m                          maxpool_percentages \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m1.0\u001B[39m, \u001B[38;5;241m2.5\u001B[39m, \u001B[38;5;241m5.0\u001B[39m, \u001B[38;5;241m10.0\u001B[39m],\n\u001B[1;32m     22\u001B[0m                          outdir\u001B[38;5;241m=\u001B[39moutdir, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, mtl_tasks\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'split_test_train_valid' is not defined"
     ]
    }
   ],
   "source": [
    "# Default values were used for most CellCNN hyperparameters,\n",
    "# except for the following: ncell = 2,000; scale = false;\n",
    "# maxpool percentages = (0.5, 1.0, 2.5, 5.0, 10.0). T\n",
    "reload_modules()\n",
    "# for regression task stratified is wrong since there are no classes\n",
    "freq_idx = 3\n",
    "cd8 = [series[freq_idx] for series in freqs]\n",
    "X_test, X_train, X_valid, cd8_test, cd8_train, cd8_valid, y_test, y_train, y_valid = split_test_train_valid(\n",
    "    X, cd8, Y,\n",
    "    train_perc=train_perc,\n",
    "    test_perc=test_perc,\n",
    "    valid_perc=0.5)\n",
    "\n",
    "# pay attention to put in phenotype first and then freq...\n",
    "model = get_fitted_model(X_train, X_valid, [y_train, cd8_train], [y_valid, cd8_valid, ],\n",
    "                         nsubset=100, ncell=2000,\n",
    "                         quant_normed=True, scale=False,\n",
    "                         nfilters=[3, 7, 20, 35], max_epochs=20,\n",
    "                         learning_rate=None, nrun=15,\n",
    "                         per_sample=True, regression=False,\n",
    "                         maxpool_percentages = [0.5, 1.0, 2.5, 5.0, 10.0],\n",
    "                         outdir=outdir, verbose=True, mtl_tasks=2)\n",
    "results = model.results\n",
    "pickle.dump(results, open(os.path.join(outdir, 'results.pkl'), 'wb'))\n",
    "save_results(results, outdir, cytokines)\n",
    "print('DONE building models')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [26]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m results \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mresults\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# exported_filter_weights: consensus filtzer from results['selected_filters'], filters_all from results['clustering_result']\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m save_results(results, outdir, cytokines)\n",
      "File \u001B[0;32m~/Documents/THESIS/cellCNN_mtl/CellCnn/cellCnn/utils.py:88\u001B[0m, in \u001B[0;36msave_results\u001B[0;34m(results, outdir, labels)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;66;03m# to get a little more information\u001B[39;00m\n\u001B[1;32m     87\u001B[0m results_log_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(csv_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresults.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 88\u001B[0m w \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mindex\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m w\u001B[38;5;241m.\u001B[39mto_csv(results_log_path, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/pandas/core/frame.py:1667\u001B[0m, in \u001B[0;36mDataFrame.from_dict\u001B[0;34m(cls, data, orient, dtype, columns)\u001B[0m\n\u001B[1;32m   1664\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1665\u001B[0m     \u001B[38;5;66;03m# TODO speed up Series case\u001B[39;00m\n\u001B[1;32m   1666\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mlist\u001B[39m(data\u001B[38;5;241m.\u001B[39mvalues())[\u001B[38;5;241m0\u001B[39m], (Series, \u001B[38;5;28mdict\u001B[39m)):\n\u001B[0;32m-> 1667\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43m_from_nested_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1668\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1669\u001B[0m         data, index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(data\u001B[38;5;241m.\u001B[39mvalues()), \u001B[38;5;28mlist\u001B[39m(data\u001B[38;5;241m.\u001B[39mkeys())\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/pandas/core/frame.py:10975\u001B[0m, in \u001B[0;36m_from_nested_dict\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m  10973\u001B[0m new_data: collections\u001B[38;5;241m.\u001B[39mdefaultdict \u001B[38;5;241m=\u001B[39m collections\u001B[38;5;241m.\u001B[39mdefaultdict(\u001B[38;5;28mdict\u001B[39m)\n\u001B[1;32m  10974\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, s \u001B[38;5;129;01min\u001B[39;00m data\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m> 10975\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m col, v \u001B[38;5;129;01min\u001B[39;00m \u001B[43ms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m():\n\u001B[1;32m  10976\u001B[0m         new_data[col][index] \u001B[38;5;241m=\u001B[39m v\n\u001B[1;32m  10977\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m new_data\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# exported_filter_weights: consensus filtzer from results['selected_filters'], filters_all from results['clustering_result']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "plotdir = os.path.join(outdir, 'plots')\n",
    "\n",
    "# consensus_filter_weights, best_net, clustered_filter_weights\n",
    "plot_filters(results, cytokines, os.path.join(plotdir, 'filter_plots'))\n",
    "\n",
    "# filter response difference.pdf -> only for consensus filters\n",
    "_v = discriminative_filters(results, os.path.join(plotdir, 'filter_plots_discriminative'),\n",
    "                            filter_diff_thres=0.2, show_filters=True)\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/seaborn/categorical.py:1296: UserWarning: 54.2% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/seaborn/categorical.py:1296: UserWarning: 45.0% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# just took default values\n",
    "# colors in plots are coming from the sample input (here the X_train)\n",
    "filter_info = plot_results(results, X_train, y_train,\n",
    "                           cytokines, os.path.join(plotdir, 'training_plots'),\n",
    "                           filter_diff_thres=0.2,\n",
    "                           filter_response_thres=0,\n",
    "                           stat_test='mannwhitneyu',\n",
    "                           group_a='RRMS', group_b='NINDC',\n",
    "                           group_names=['RRMS', 'NINDC'],\n",
    "                           tsne_ncell=1000,\n",
    "                           regression=False,\n",
    "                           show_filters=True)\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/eliasschreiner/.local/share/virtualenvs/THESIS-UFQOor4v/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_v = plot_results(results, X_valid, y_valid,\n",
    "                  cytokines, os.path.join(plotdir, 'validation_plots'),\n",
    "                  filter_diff_thres=0.2,\n",
    "                  filter_response_thres=0,\n",
    "                  stat_test='mannwhitneyu',\n",
    "                  group_a='RRMS', group_b='NINDC',\n",
    "                  group_names=['Test_a', 'test_b'],\n",
    "                  tsne_ncell=1000,\n",
    "                  regression=False,\n",
    "                  show_filters=True)\n",
    "csv_dir = os.path.join(outdir, 'selected_cells')\n",
    "mkdir_p(csv_dir)\n",
    "nfilter = len(filter_info)\n",
    "\n",
    "# args.fcs = des gibt mir die fcs folder ich hol mir in sample names also die verschiedenen fcs filenames raus...\n",
    "# ich arbeite nur mit einem fcs file  (ich nutze ja nur den cohort), drum verteil ich den name jetzt einfach"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m sample_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mselected_cells/cohort\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m----> 2\u001B[0m df2 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(indir, infile), index_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      3\u001B[0m df2 \u001B[38;5;241m=\u001B[39m df2\u001B[38;5;241m.\u001B[39mdrop_duplicates()\n\u001B[1;32m      4\u001B[0m test \u001B[38;5;241m=\u001B[39m df2\u001B[38;5;241m.\u001B[39miloc[:, :\u001B[38;5;28mlen\u001B[39m(cytokines)]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'indir' is not defined"
     ]
    }
   ],
   "source": [
    "sample_names = ['selected_cells/cohort']\n",
    "df2 = pd.read_csv(os.path.join(indir, infile), index_col=0)\n",
    "df2 = df2.drop_duplicates()\n",
    "test = df2.iloc[:, :len(cytokines)]\n",
    "samples = [test]\n",
    "# for each sample\n",
    "for x, x_name in zip(samples, sample_names):\n",
    "    flags = np.zeros((x.shape[0], 2 * nfilter))\n",
    "    columns = []\n",
    "    # for each filter\n",
    "    for i, (filter_idx, thres) in enumerate(filter_info):\n",
    "        flags[:, 2 * i:2 * (i + 1)] = get_selected_cells(\n",
    "            results['selected_filters'][filter_idx], x, results['scaler'], thres, True)\n",
    "        columns += ['filter_%d_continuous' % filter_idx, 'filter_%d_binary' % filter_idx]\n",
    "    df = pd.DataFrame(flags, columns=columns)\n",
    "    df.to_csv(os.path.join(outdir, x_name + '_selected_cells.csv'), index=False)\n",
    "\n",
    "print('done')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write stats to: \n",
      "\n",
      "class_cd8/stats_class_2000_100.txt\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13d922700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13e12e310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "CALLING...\n",
      "in mtl: split inputs\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "reload_modules()\n",
    "######################################################################\n",
    "# what predict does is: Iterating over the best 3 nets and return an array per net with the predictions for all samples!\n",
    "stats_file = open(f\"{outdir}/stats_class_{model.ncell}_{model.nsubset}.txt\", \"w+\")\n",
    "print('Write stats to: \\n')\n",
    "print(stats_file.name)\n",
    "\n",
    "stats_file.write(f\"CellCNN Model {outdir}  with ncells: {model.ncell} and subsets: {model.nsubset}\\n\")\n",
    "stats_file.write(f\"Best model was {model.results['best_model_index']} \\n\")\n",
    "\n",
    "test_pred = model.predict(X_test, mtl_inputs=[y_test, cd8_test])\n",
    "train_pred = model.predict(X_train, mtl_inputs=[y_train, cd8_train])\n",
    "valid_pred = model.predict(X_valid, mtl_inputs=[y_valid, cd8_valid])\n",
    "#print_regression_model_stats(test_pred, b_test)\n",
    "test_pred_abs = [1 if pred[0] > pred[1] else 0 for pred in test_pred[0]]\n",
    "train_pred_abs = [1 if pred[0] > pred[1] else 0 for pred in train_pred[0]]\n",
    "valid_pred_abs = [1 if pred[0] > pred[1] else 0 for pred in valid_pred[0]]\n",
    "\n",
    "acc_test = accuracy_score(list(y_test), test_pred_abs)\n",
    "acc_train = accuracy_score(list(y_train), train_pred_abs)\n",
    "acc_valid = accuracy_score(list(y_valid), valid_pred_abs)\n",
    "stats_file.write('Desease: \\n')\n",
    "stats_file.write(f'Acc y test {acc_test}\\n')\n",
    "stats_file.write(f'Acc y train {acc_train}\\n')\n",
    "stats_file.write(f'Acc y valid {acc_valid}\\n')\n",
    "\n",
    "mse_test_cd8 = mean_squared_error(list(cd8_test), test_pred[1])\n",
    "mse_train_cd8 = mean_squared_error(list(cd8_train), train_pred[1])\n",
    "mse_valid_cd8 = mean_squared_error(list(cd8_valid), valid_pred[1])\n",
    "stats_file.write('Cd8: \\n')\n",
    "stats_file.write(f'MSE y test {mse_test_cd8}\\n')\n",
    "stats_file.write(f'MSE y train {mse_train_cd8}\\n')\n",
    "stats_file.write(f'MSE y valid {mse_valid_cd8}\\n')\n",
    "stats_file.write('\\n')\n",
    "stats_file.close()\n",
    "print('DONE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f8b1a153",
   "language": "python",
   "display_name": "PyCharm (cellCNN_mtl)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}